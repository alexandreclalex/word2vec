{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstrate Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from CONFIG import PREPROCESSED_DATA_PATH\n",
    "from knn import KNN\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader\n",
    "from classifier import Classifier\n",
    "from word2vec import Word2VecModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_parquet(PREPROCESSED_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Title Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word2vec = gensim.downloader.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_word_embeddings(title):\n",
    "    word_embeddings = [word2vec[x] for x in title.split() if x in word2vec]\n",
    "    if len(word_embeddings) == 0:\n",
    "        word_embeddings = np.zeros((1, 300))\n",
    "    word_embeddings = np.array(word_embeddings)\n",
    "    return np.mean(word_embeddings, axis=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_subset = df_data[:100]\n",
    "train_subset = df_data[100:10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify Using Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word2vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ce0d316bdc0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_average_word_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_subset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"title\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtraining_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_subset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"categories\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-ce0d316bdc0d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_average_word_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_subset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"title\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtraining_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_subset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"categories\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-3e4f2ce3e9ed>\u001b[0m in \u001b[0;36mget_average_word_embeddings\u001b[0;34m(title)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_average_word_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mword_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword2vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mword_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mword_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-3e4f2ce3e9ed>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_average_word_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mword_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword2vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mword_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mword_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'word2vec' is not defined"
     ]
    }
   ],
   "source": [
    "training_vectors = [get_average_word_embeddings(x) for x in train_subset[\"title\"]]\n",
    "training_classes = train_subset[\"categories\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9900, 10)\n",
      "Epoch 1/1024\n",
      "9/9 - 0s - loss: 0.6926\n",
      "Epoch 2/1024\n",
      "9/9 - 0s - loss: 0.6911\n",
      "Epoch 3/1024\n",
      "9/9 - 0s - loss: 0.6890\n",
      "Epoch 4/1024\n",
      "9/9 - 0s - loss: 0.6866\n",
      "Epoch 5/1024\n",
      "9/9 - 0s - loss: 0.6835\n",
      "Epoch 6/1024\n",
      "9/9 - 0s - loss: 0.6799\n",
      "Epoch 7/1024\n",
      "9/9 - 0s - loss: 0.6750\n",
      "Epoch 8/1024\n",
      "9/9 - 0s - loss: 0.6716\n",
      "Epoch 9/1024\n",
      "9/9 - 0s - loss: 0.6651\n",
      "Epoch 10/1024\n",
      "9/9 - 0s - loss: 0.6609\n",
      "Epoch 11/1024\n",
      "9/9 - 0s - loss: 0.6553\n",
      "Epoch 12/1024\n",
      "9/9 - 0s - loss: 0.6488\n",
      "Epoch 13/1024\n",
      "9/9 - 0s - loss: 0.6432\n",
      "Epoch 14/1024\n",
      "9/9 - 0s - loss: 0.6365\n",
      "Epoch 15/1024\n",
      "9/9 - 0s - loss: 0.6322\n",
      "Epoch 16/1024\n",
      "9/9 - 0s - loss: 0.6232\n",
      "Epoch 17/1024\n",
      "9/9 - 0s - loss: 0.6210\n",
      "Epoch 18/1024\n",
      "9/9 - 0s - loss: 0.6134\n",
      "Epoch 19/1024\n",
      "9/9 - 0s - loss: 0.6080\n",
      "Epoch 20/1024\n",
      "9/9 - 0s - loss: 0.5997\n",
      "Epoch 21/1024\n",
      "9/9 - 0s - loss: 0.5980\n",
      "Epoch 22/1024\n",
      "9/9 - 0s - loss: 0.5904\n",
      "Epoch 23/1024\n",
      "9/9 - 0s - loss: 0.5846\n",
      "Epoch 24/1024\n",
      "9/9 - 0s - loss: 0.5848\n",
      "Epoch 25/1024\n",
      "9/9 - 0s - loss: 0.5818\n",
      "Epoch 26/1024\n",
      "9/9 - 0s - loss: 0.5773\n",
      "Epoch 27/1024\n",
      "9/9 - 0s - loss: 0.5754\n",
      "Epoch 28/1024\n",
      "9/9 - 0s - loss: 0.5688\n",
      "Epoch 29/1024\n",
      "9/9 - 0s - loss: 0.5690\n",
      "Epoch 30/1024\n",
      "9/9 - 0s - loss: 0.5694\n",
      "Epoch 31/1024\n",
      "9/9 - 0s - loss: 0.5572\n",
      "Epoch 32/1024\n",
      "9/9 - 0s - loss: 0.5646\n",
      "Epoch 33/1024\n",
      "9/9 - 0s - loss: 0.5595\n",
      "Epoch 34/1024\n",
      "9/9 - 0s - loss: 0.5614\n",
      "Epoch 35/1024\n",
      "9/9 - 0s - loss: 0.5574\n",
      "Epoch 36/1024\n",
      "9/9 - 0s - loss: 0.5525\n",
      "Epoch 37/1024\n",
      "9/9 - 0s - loss: 0.5516\n",
      "Epoch 38/1024\n",
      "9/9 - 0s - loss: 0.5434\n",
      "Epoch 39/1024\n",
      "9/9 - 0s - loss: 0.5431\n",
      "Epoch 40/1024\n",
      "9/9 - 0s - loss: 0.5463\n",
      "Epoch 41/1024\n",
      "9/9 - 0s - loss: 0.5448\n",
      "Epoch 42/1024\n",
      "9/9 - 0s - loss: 0.5545\n",
      "Epoch 43/1024\n",
      "9/9 - 0s - loss: 0.5435\n",
      "Epoch 44/1024\n",
      "9/9 - 0s - loss: 0.5417\n",
      "Epoch 45/1024\n",
      "9/9 - 0s - loss: 0.5409\n",
      "Epoch 46/1024\n",
      "9/9 - 0s - loss: 0.5384\n",
      "Epoch 47/1024\n",
      "9/9 - 0s - loss: 0.5433\n",
      "Epoch 48/1024\n",
      "9/9 - 0s - loss: 0.5406\n",
      "Epoch 49/1024\n",
      "9/9 - 0s - loss: 0.5316\n",
      "Epoch 50/1024\n",
      "9/9 - 0s - loss: 0.5413\n",
      "Epoch 51/1024\n",
      "9/9 - 0s - loss: 0.5328\n",
      "Epoch 52/1024\n",
      "9/9 - 0s - loss: 0.5317\n",
      "Epoch 53/1024\n",
      "9/9 - 0s - loss: 0.5265\n",
      "Epoch 54/1024\n",
      "9/9 - 0s - loss: 0.5380\n",
      "Epoch 55/1024\n",
      "9/9 - 0s - loss: 0.5294\n",
      "Epoch 56/1024\n",
      "9/9 - 0s - loss: 0.5252\n",
      "Epoch 57/1024\n",
      "9/9 - 0s - loss: 0.5374\n",
      "Epoch 58/1024\n",
      "9/9 - 0s - loss: 0.5273\n",
      "Epoch 59/1024\n",
      "9/9 - 0s - loss: 0.5266\n",
      "Epoch 60/1024\n",
      "9/9 - 0s - loss: 0.5215\n",
      "Epoch 61/1024\n",
      "9/9 - 0s - loss: 0.5259\n",
      "Epoch 62/1024\n",
      "9/9 - 0s - loss: 0.5260\n",
      "Epoch 63/1024\n",
      "9/9 - 0s - loss: 0.5249\n",
      "Epoch 64/1024\n",
      "9/9 - 0s - loss: 0.5235\n",
      "Epoch 65/1024\n",
      "9/9 - 0s - loss: 0.5193\n",
      "Epoch 66/1024\n",
      "9/9 - 0s - loss: 0.5228\n",
      "Epoch 67/1024\n",
      "9/9 - 0s - loss: 0.5272\n",
      "Epoch 68/1024\n",
      "9/9 - 0s - loss: 0.5197\n",
      "Epoch 69/1024\n",
      "9/9 - 0s - loss: 0.5194\n",
      "Epoch 70/1024\n",
      "9/9 - 0s - loss: 0.5151\n",
      "Epoch 71/1024\n",
      "9/9 - 0s - loss: 0.5184\n",
      "Epoch 72/1024\n",
      "9/9 - 0s - loss: 0.5212\n",
      "Epoch 73/1024\n",
      "9/9 - 0s - loss: 0.5197\n",
      "Epoch 74/1024\n",
      "9/9 - 0s - loss: 0.5177\n",
      "Epoch 75/1024\n",
      "9/9 - 0s - loss: 0.5185\n",
      "Epoch 76/1024\n",
      "9/9 - 0s - loss: 0.5120\n",
      "Epoch 77/1024\n",
      "9/9 - 0s - loss: 0.5236\n",
      "Epoch 78/1024\n",
      "9/9 - 0s - loss: 0.5131\n",
      "Epoch 79/1024\n",
      "9/9 - 0s - loss: 0.5145\n",
      "Epoch 80/1024\n",
      "9/9 - 0s - loss: 0.5107\n",
      "Epoch 81/1024\n",
      "9/9 - 0s - loss: 0.5105\n",
      "Epoch 82/1024\n",
      "9/9 - 0s - loss: 0.5191\n",
      "Epoch 83/1024\n",
      "9/9 - 0s - loss: 0.5153\n",
      "Epoch 84/1024\n",
      "9/9 - 0s - loss: 0.5026\n",
      "Epoch 85/1024\n",
      "9/9 - 0s - loss: 0.5106\n",
      "Epoch 86/1024\n",
      "9/9 - 0s - loss: 0.5084\n",
      "Epoch 87/1024\n",
      "9/9 - 0s - loss: 0.5076\n",
      "Epoch 88/1024\n",
      "9/9 - 0s - loss: 0.5125\n",
      "Epoch 89/1024\n",
      "9/9 - 0s - loss: 0.5075\n",
      "Epoch 90/1024\n",
      "9/9 - 0s - loss: 0.5101\n",
      "Epoch 91/1024\n",
      "9/9 - 0s - loss: 0.5086\n",
      "Epoch 92/1024\n",
      "9/9 - 0s - loss: 0.5088\n",
      "Epoch 93/1024\n",
      "9/9 - 0s - loss: 0.5063\n",
      "Epoch 94/1024\n",
      "9/9 - 0s - loss: 0.5073\n",
      "Epoch 95/1024\n",
      "9/9 - 0s - loss: 0.5046\n",
      "Epoch 96/1024\n",
      "9/9 - 0s - loss: 0.4929\n",
      "Epoch 97/1024\n",
      "9/9 - 0s - loss: 0.5031\n",
      "Epoch 98/1024\n",
      "9/9 - 0s - loss: 0.4973\n",
      "Epoch 99/1024\n",
      "9/9 - 0s - loss: 0.4994\n",
      "Epoch 100/1024\n",
      "9/9 - 0s - loss: 0.5065\n",
      "Epoch 101/1024\n",
      "9/9 - 0s - loss: 0.5005\n",
      "Epoch 102/1024\n",
      "9/9 - 0s - loss: 0.5007\n",
      "Epoch 103/1024\n",
      "9/9 - 0s - loss: 0.4942\n",
      "Epoch 104/1024\n",
      "9/9 - 0s - loss: 0.4983\n",
      "Epoch 105/1024\n",
      "9/9 - 0s - loss: 0.5011\n",
      "Epoch 106/1024\n",
      "9/9 - 0s - loss: 0.4988\n",
      "Epoch 107/1024\n",
      "9/9 - 0s - loss: 0.4957\n",
      "Epoch 108/1024\n",
      "9/9 - 0s - loss: 0.4987\n",
      "Epoch 109/1024\n",
      "9/9 - 0s - loss: 0.4960\n",
      "Epoch 110/1024\n",
      "9/9 - 0s - loss: 0.4947\n",
      "Epoch 111/1024\n",
      "9/9 - 0s - loss: 0.4916\n",
      "Epoch 112/1024\n",
      "9/9 - 0s - loss: 0.5056\n",
      "Epoch 113/1024\n",
      "9/9 - 0s - loss: 0.4895\n",
      "Epoch 114/1024\n",
      "9/9 - 0s - loss: 0.4939\n",
      "Epoch 115/1024\n",
      "9/9 - 0s - loss: 0.4871\n",
      "Epoch 116/1024\n",
      "9/9 - 0s - loss: 0.4922\n",
      "Epoch 117/1024\n",
      "9/9 - 0s - loss: 0.4869\n",
      "Epoch 118/1024\n",
      "9/9 - 0s - loss: 0.4891\n",
      "Epoch 119/1024\n",
      "9/9 - 0s - loss: 0.4959\n",
      "Epoch 120/1024\n",
      "9/9 - 0s - loss: 0.4852\n",
      "Epoch 121/1024\n",
      "9/9 - 0s - loss: 0.4885\n",
      "Epoch 122/1024\n",
      "9/9 - 0s - loss: 0.4938\n",
      "Epoch 123/1024\n",
      "9/9 - 0s - loss: 0.4815\n",
      "Epoch 124/1024\n",
      "9/9 - 0s - loss: 0.4929\n",
      "Epoch 125/1024\n",
      "9/9 - 0s - loss: 0.4869\n",
      "Epoch 126/1024\n",
      "9/9 - 0s - loss: 0.4822\n",
      "Epoch 127/1024\n",
      "9/9 - 0s - loss: 0.4836\n",
      "Epoch 128/1024\n",
      "9/9 - 0s - loss: 0.4831\n",
      "Epoch 129/1024\n",
      "9/9 - 0s - loss: 0.4840\n",
      "Epoch 130/1024\n",
      "9/9 - 0s - loss: 0.4792\n",
      "Epoch 131/1024\n",
      "9/9 - 0s - loss: 0.4896\n",
      "Epoch 132/1024\n",
      "9/9 - 0s - loss: 0.4816\n",
      "Epoch 133/1024\n",
      "9/9 - 0s - loss: 0.4821\n",
      "Epoch 134/1024\n",
      "9/9 - 0s - loss: 0.4851\n",
      "Epoch 135/1024\n",
      "9/9 - 0s - loss: 0.4763\n",
      "Epoch 136/1024\n",
      "9/9 - 0s - loss: 0.4885\n",
      "Epoch 137/1024\n",
      "9/9 - 0s - loss: 0.4835\n",
      "Epoch 138/1024\n",
      "9/9 - 0s - loss: 0.4791\n",
      "Epoch 139/1024\n",
      "9/9 - 0s - loss: 0.4820\n",
      "Epoch 140/1024\n",
      "9/9 - 0s - loss: 0.4764\n",
      "Epoch 141/1024\n",
      "9/9 - 0s - loss: 0.4708\n",
      "Epoch 142/1024\n",
      "9/9 - 0s - loss: 0.4747\n",
      "Epoch 143/1024\n",
      "9/9 - 0s - loss: 0.4800\n",
      "Epoch 144/1024\n",
      "9/9 - 0s - loss: 0.4839\n",
      "Epoch 145/1024\n",
      "9/9 - 0s - loss: 0.4737\n",
      "Epoch 146/1024\n",
      "9/9 - 0s - loss: 0.4821\n",
      "Epoch 147/1024\n",
      "9/9 - 0s - loss: 0.4683\n",
      "Epoch 148/1024\n",
      "9/9 - 0s - loss: 0.4753\n",
      "Epoch 149/1024\n",
      "9/9 - 0s - loss: 0.4665\n",
      "Epoch 150/1024\n",
      "9/9 - 0s - loss: 0.4757\n",
      "Epoch 151/1024\n",
      "9/9 - 0s - loss: 0.4729\n",
      "Epoch 152/1024\n",
      "9/9 - 0s - loss: 0.4717\n",
      "Epoch 153/1024\n",
      "9/9 - 0s - loss: 0.4715\n",
      "Epoch 154/1024\n",
      "9/9 - 0s - loss: 0.4682\n",
      "Epoch 155/1024\n",
      "9/9 - 0s - loss: 0.4774\n",
      "Epoch 156/1024\n",
      "9/9 - 0s - loss: 0.4681\n",
      "Epoch 157/1024\n",
      "9/9 - 0s - loss: 0.4697\n",
      "Epoch 158/1024\n",
      "9/9 - 0s - loss: 0.4710\n",
      "Epoch 159/1024\n",
      "9/9 - 0s - loss: 0.4617\n",
      "Epoch 160/1024\n",
      "9/9 - 0s - loss: 0.4749\n",
      "Epoch 161/1024\n",
      "9/9 - 0s - loss: 0.4751\n",
      "Epoch 162/1024\n",
      "9/9 - 0s - loss: 0.4683\n",
      "Epoch 163/1024\n",
      "9/9 - 0s - loss: 0.4680\n",
      "Epoch 164/1024\n",
      "9/9 - 0s - loss: 0.4721\n",
      "Epoch 165/1024\n",
      "9/9 - 0s - loss: 0.4698\n",
      "Epoch 166/1024\n",
      "9/9 - 0s - loss: 0.4654\n",
      "Epoch 167/1024\n",
      "9/9 - 0s - loss: 0.4656\n",
      "Epoch 168/1024\n",
      "9/9 - 0s - loss: 0.4643\n",
      "Epoch 169/1024\n",
      "9/9 - 0s - loss: 0.4655\n",
      "Epoch 170/1024\n",
      "9/9 - 0s - loss: 0.4646\n",
      "Epoch 171/1024\n",
      "9/9 - 0s - loss: 0.4688\n",
      "Epoch 172/1024\n",
      "9/9 - 0s - loss: 0.4600\n",
      "Epoch 173/1024\n",
      "9/9 - 0s - loss: 0.4714\n",
      "Epoch 174/1024\n",
      "9/9 - 0s - loss: 0.4610\n",
      "Epoch 175/1024\n",
      "9/9 - 0s - loss: 0.4551\n",
      "Epoch 176/1024\n",
      "9/9 - 0s - loss: 0.4588\n",
      "Epoch 177/1024\n",
      "9/9 - 0s - loss: 0.4605\n",
      "Epoch 178/1024\n",
      "9/9 - 0s - loss: 0.4590\n",
      "Epoch 179/1024\n",
      "9/9 - 0s - loss: 0.4491\n",
      "Epoch 180/1024\n",
      "9/9 - 0s - loss: 0.4600\n",
      "Epoch 181/1024\n",
      "9/9 - 0s - loss: 0.4601\n",
      "Epoch 182/1024\n",
      "9/9 - 0s - loss: 0.4663\n",
      "Epoch 183/1024\n",
      "9/9 - 0s - loss: 0.4563\n",
      "Epoch 184/1024\n",
      "9/9 - 0s - loss: 0.4590\n",
      "Epoch 185/1024\n",
      "9/9 - 0s - loss: 0.4595\n",
      "Epoch 186/1024\n",
      "9/9 - 0s - loss: 0.4534\n",
      "Epoch 187/1024\n",
      "9/9 - 0s - loss: 0.4545\n",
      "Epoch 188/1024\n",
      "9/9 - 0s - loss: 0.4479\n",
      "Epoch 189/1024\n",
      "9/9 - 0s - loss: 0.4572\n",
      "Epoch 190/1024\n",
      "9/9 - 0s - loss: 0.4579\n",
      "Epoch 191/1024\n",
      "9/9 - 0s - loss: 0.4489\n",
      "Epoch 192/1024\n",
      "9/9 - 0s - loss: 0.4437\n",
      "Epoch 193/1024\n",
      "9/9 - 0s - loss: 0.4541\n",
      "Epoch 194/1024\n",
      "9/9 - 0s - loss: 0.4540\n",
      "Epoch 195/1024\n",
      "9/9 - 0s - loss: 0.4482\n",
      "Epoch 196/1024\n",
      "9/9 - 0s - loss: 0.4619\n",
      "Epoch 197/1024\n",
      "9/9 - 0s - loss: 0.4596\n",
      "Epoch 198/1024\n",
      "9/9 - 0s - loss: 0.4510\n",
      "Epoch 199/1024\n",
      "9/9 - 0s - loss: 0.4436\n",
      "Epoch 200/1024\n",
      "9/9 - 0s - loss: 0.4434\n",
      "Epoch 201/1024\n",
      "9/9 - 0s - loss: 0.4488\n",
      "Epoch 202/1024\n",
      "9/9 - 0s - loss: 0.4364\n",
      "Epoch 203/1024\n",
      "9/9 - 0s - loss: 0.4490\n",
      "Epoch 204/1024\n",
      "9/9 - 0s - loss: 0.4508\n",
      "Epoch 205/1024\n",
      "9/9 - 0s - loss: 0.4562\n",
      "Epoch 206/1024\n",
      "9/9 - 0s - loss: 0.4401\n",
      "Epoch 207/1024\n",
      "9/9 - 0s - loss: 0.4455\n",
      "Epoch 208/1024\n",
      "9/9 - 0s - loss: 0.4557\n",
      "Epoch 209/1024\n",
      "9/9 - 0s - loss: 0.4512\n",
      "Epoch 210/1024\n",
      "9/9 - 0s - loss: 0.4486\n",
      "Epoch 211/1024\n",
      "9/9 - 0s - loss: 0.4557\n",
      "Epoch 212/1024\n",
      "9/9 - 0s - loss: 0.4468\n",
      "Epoch 213/1024\n",
      "9/9 - 0s - loss: 0.4501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 214/1024\n",
      "9/9 - 0s - loss: 0.4457\n",
      "Epoch 215/1024\n",
      "9/9 - 0s - loss: 0.4340\n",
      "Epoch 216/1024\n",
      "9/9 - 0s - loss: 0.4375\n",
      "Epoch 217/1024\n",
      "9/9 - 0s - loss: 0.4338\n",
      "Epoch 218/1024\n",
      "9/9 - 0s - loss: 0.4418\n",
      "Epoch 219/1024\n",
      "9/9 - 0s - loss: 0.4362\n",
      "Epoch 220/1024\n",
      "9/9 - 0s - loss: 0.4429\n",
      "Epoch 221/1024\n",
      "9/9 - 0s - loss: 0.4431\n",
      "Epoch 222/1024\n",
      "9/9 - 0s - loss: 0.4447\n",
      "Epoch 223/1024\n",
      "9/9 - 0s - loss: 0.4449\n",
      "Epoch 224/1024\n",
      "9/9 - 0s - loss: 0.4336\n",
      "Epoch 225/1024\n",
      "9/9 - 0s - loss: 0.4362\n",
      "Epoch 226/1024\n",
      "9/9 - 0s - loss: 0.4312\n",
      "Epoch 227/1024\n",
      "9/9 - 0s - loss: 0.4466\n",
      "Epoch 228/1024\n",
      "9/9 - 0s - loss: 0.4360\n",
      "Epoch 229/1024\n",
      "9/9 - 0s - loss: 0.4381\n",
      "Epoch 230/1024\n",
      "9/9 - 0s - loss: 0.4262\n",
      "Epoch 231/1024\n",
      "9/9 - 0s - loss: 0.4342\n",
      "Epoch 232/1024\n",
      "9/9 - 0s - loss: 0.4324\n",
      "Epoch 233/1024\n",
      "9/9 - 0s - loss: 0.4425\n",
      "Epoch 234/1024\n",
      "9/9 - 0s - loss: 0.4365\n",
      "Epoch 235/1024\n",
      "9/9 - 0s - loss: 0.4282\n",
      "Epoch 236/1024\n",
      "9/9 - 0s - loss: 0.4301\n",
      "Epoch 237/1024\n",
      "9/9 - 0s - loss: 0.4346\n",
      "Epoch 238/1024\n",
      "9/9 - 0s - loss: 0.4319\n",
      "Epoch 239/1024\n",
      "9/9 - 0s - loss: 0.4341\n",
      "Epoch 240/1024\n",
      "9/9 - 0s - loss: 0.4322\n",
      "Epoch 241/1024\n",
      "9/9 - 0s - loss: 0.4314\n",
      "Epoch 242/1024\n",
      "9/9 - 0s - loss: 0.4323\n",
      "Epoch 243/1024\n",
      "9/9 - 0s - loss: 0.4415\n",
      "Epoch 244/1024\n",
      "9/9 - 0s - loss: 0.4292\n",
      "Epoch 245/1024\n",
      "9/9 - 0s - loss: 0.4395\n",
      "Epoch 246/1024\n",
      "9/9 - 0s - loss: 0.4387\n",
      "Epoch 247/1024\n",
      "9/9 - 0s - loss: 0.4263\n",
      "Epoch 248/1024\n",
      "9/9 - 0s - loss: 0.4319\n",
      "Epoch 249/1024\n",
      "9/9 - 0s - loss: 0.4366\n",
      "Epoch 250/1024\n",
      "9/9 - 0s - loss: 0.4349\n",
      "Epoch 251/1024\n",
      "9/9 - 0s - loss: 0.4331\n",
      "Epoch 252/1024\n",
      "9/9 - 0s - loss: 0.4339\n",
      "Epoch 253/1024\n",
      "9/9 - 0s - loss: 0.4284\n",
      "Epoch 254/1024\n",
      "9/9 - 0s - loss: 0.4253\n",
      "Epoch 255/1024\n",
      "9/9 - 0s - loss: 0.4317\n",
      "Epoch 256/1024\n",
      "9/9 - 0s - loss: 0.4338\n",
      "Epoch 257/1024\n",
      "9/9 - 0s - loss: 0.4295\n",
      "Epoch 258/1024\n",
      "9/9 - 0s - loss: 0.4343\n",
      "Epoch 259/1024\n",
      "9/9 - 0s - loss: 0.4326\n",
      "Epoch 260/1024\n",
      "9/9 - 0s - loss: 0.4346\n",
      "Epoch 261/1024\n",
      "9/9 - 0s - loss: 0.4303\n",
      "Epoch 262/1024\n",
      "9/9 - 0s - loss: 0.4270\n",
      "Epoch 263/1024\n",
      "9/9 - 0s - loss: 0.4340\n",
      "Epoch 264/1024\n",
      "9/9 - 0s - loss: 0.4227\n",
      "Epoch 265/1024\n",
      "9/9 - 0s - loss: 0.4110\n",
      "Epoch 266/1024\n",
      "9/9 - 0s - loss: 0.4245\n",
      "Epoch 267/1024\n",
      "9/9 - 0s - loss: 0.4329\n",
      "Epoch 268/1024\n",
      "9/9 - 0s - loss: 0.4201\n",
      "Epoch 269/1024\n",
      "9/9 - 0s - loss: 0.4132\n",
      "Epoch 270/1024\n",
      "9/9 - 0s - loss: 0.4211\n",
      "Epoch 271/1024\n",
      "9/9 - 0s - loss: 0.4196\n",
      "Epoch 272/1024\n",
      "9/9 - 0s - loss: 0.4226\n",
      "Epoch 273/1024\n",
      "9/9 - 0s - loss: 0.4240\n",
      "Epoch 274/1024\n",
      "9/9 - 0s - loss: 0.4136\n",
      "Epoch 275/1024\n",
      "9/9 - 0s - loss: 0.4227\n",
      "Epoch 276/1024\n",
      "9/9 - 0s - loss: 0.4209\n",
      "Epoch 277/1024\n",
      "9/9 - 0s - loss: 0.4236\n",
      "Epoch 278/1024\n",
      "9/9 - 0s - loss: 0.4256\n",
      "Epoch 279/1024\n",
      "9/9 - 0s - loss: 0.4269\n",
      "Epoch 280/1024\n",
      "9/9 - 0s - loss: 0.4313\n",
      "Epoch 281/1024\n",
      "9/9 - 0s - loss: 0.4179\n",
      "Epoch 282/1024\n",
      "9/9 - 0s - loss: 0.4248\n",
      "Epoch 283/1024\n",
      "9/9 - 0s - loss: 0.4219\n",
      "Epoch 284/1024\n",
      "9/9 - 0s - loss: 0.4200\n",
      "Epoch 285/1024\n",
      "9/9 - 0s - loss: 0.4249\n",
      "Epoch 286/1024\n",
      "9/9 - 0s - loss: 0.4174\n",
      "Epoch 287/1024\n",
      "9/9 - 0s - loss: 0.4208\n",
      "Epoch 288/1024\n",
      "9/9 - 0s - loss: 0.4252\n",
      "Epoch 289/1024\n",
      "9/9 - 0s - loss: 0.4186\n",
      "Epoch 290/1024\n",
      "9/9 - 0s - loss: 0.4183\n",
      "Epoch 291/1024\n",
      "9/9 - 0s - loss: 0.4265\n",
      "Epoch 292/1024\n",
      "9/9 - 0s - loss: 0.4174\n",
      "Epoch 293/1024\n",
      "9/9 - 0s - loss: 0.4199\n",
      "Epoch 294/1024\n",
      "9/9 - 0s - loss: 0.4079\n",
      "Epoch 295/1024\n",
      "9/9 - 0s - loss: 0.4202\n",
      "Epoch 296/1024\n",
      "9/9 - 0s - loss: 0.4194\n",
      "Epoch 297/1024\n",
      "9/9 - 0s - loss: 0.4168\n",
      "Epoch 298/1024\n",
      "9/9 - 0s - loss: 0.4173\n",
      "Epoch 299/1024\n",
      "9/9 - 0s - loss: 0.4075\n",
      "Epoch 300/1024\n",
      "9/9 - 0s - loss: 0.4125\n",
      "Epoch 301/1024\n",
      "9/9 - 0s - loss: 0.4167\n",
      "Epoch 302/1024\n",
      "9/9 - 0s - loss: 0.4176\n",
      "Epoch 303/1024\n",
      "9/9 - 0s - loss: 0.4138\n",
      "Epoch 304/1024\n",
      "9/9 - 0s - loss: 0.4173\n",
      "Epoch 305/1024\n",
      "9/9 - 0s - loss: 0.4153\n",
      "Epoch 306/1024\n",
      "9/9 - 0s - loss: 0.4094\n",
      "Epoch 307/1024\n",
      "9/9 - 0s - loss: 0.4132\n",
      "Epoch 308/1024\n",
      "9/9 - 0s - loss: 0.4111\n",
      "Epoch 309/1024\n",
      "9/9 - 0s - loss: 0.4089\n",
      "Epoch 310/1024\n",
      "9/9 - 0s - loss: 0.4080\n",
      "Epoch 311/1024\n",
      "9/9 - 0s - loss: 0.4145\n",
      "Epoch 312/1024\n",
      "9/9 - 0s - loss: 0.4155\n",
      "Epoch 313/1024\n",
      "9/9 - 0s - loss: 0.4219\n",
      "Epoch 314/1024\n",
      "9/9 - 0s - loss: 0.4160\n",
      "Epoch 315/1024\n",
      "9/9 - 0s - loss: 0.4122\n",
      "Epoch 316/1024\n",
      "9/9 - 0s - loss: 0.4135\n",
      "Epoch 317/1024\n",
      "9/9 - 0s - loss: 0.4171\n",
      "Epoch 318/1024\n",
      "9/9 - 0s - loss: 0.4181\n",
      "Epoch 319/1024\n",
      "9/9 - 0s - loss: 0.4156\n",
      "Epoch 320/1024\n",
      "9/9 - 0s - loss: 0.4150\n",
      "Epoch 321/1024\n",
      "9/9 - 0s - loss: 0.4220\n",
      "Epoch 322/1024\n",
      "9/9 - 0s - loss: 0.4090\n",
      "Epoch 323/1024\n",
      "9/9 - 0s - loss: 0.3954\n",
      "Epoch 324/1024\n",
      "9/9 - 0s - loss: 0.4066\n",
      "Epoch 325/1024\n",
      "9/9 - 0s - loss: 0.4258\n",
      "Epoch 326/1024\n",
      "9/9 - 0s - loss: 0.4181\n",
      "Epoch 327/1024\n",
      "9/9 - 0s - loss: 0.4207\n",
      "Epoch 328/1024\n",
      "9/9 - 0s - loss: 0.4173\n",
      "Epoch 329/1024\n",
      "9/9 - 0s - loss: 0.4095\n",
      "Epoch 330/1024\n",
      "9/9 - 0s - loss: 0.4019\n",
      "Epoch 331/1024\n",
      "9/9 - 0s - loss: 0.4062\n",
      "Epoch 332/1024\n",
      "9/9 - 0s - loss: 0.4052\n",
      "Epoch 333/1024\n",
      "9/9 - 0s - loss: 0.4062\n",
      "Epoch 334/1024\n",
      "9/9 - 0s - loss: 0.4029\n",
      "Epoch 335/1024\n",
      "9/9 - 0s - loss: 0.4103\n",
      "Epoch 336/1024\n",
      "9/9 - 0s - loss: 0.4048\n",
      "Epoch 337/1024\n",
      "9/9 - 0s - loss: 0.4056\n",
      "Epoch 338/1024\n",
      "9/9 - 0s - loss: 0.4105\n",
      "Epoch 339/1024\n",
      "9/9 - 0s - loss: 0.4107\n",
      "Epoch 340/1024\n",
      "9/9 - 0s - loss: 0.4010\n",
      "Epoch 341/1024\n",
      "9/9 - 0s - loss: 0.3982\n",
      "Epoch 342/1024\n",
      "9/9 - 0s - loss: 0.4141\n",
      "Epoch 343/1024\n",
      "9/9 - 0s - loss: 0.3991\n",
      "Epoch 344/1024\n",
      "9/9 - 0s - loss: 0.4111\n",
      "Epoch 345/1024\n",
      "9/9 - 0s - loss: 0.4092\n",
      "Epoch 346/1024\n",
      "9/9 - 0s - loss: 0.3996\n",
      "Epoch 347/1024\n",
      "9/9 - 0s - loss: 0.4056\n",
      "Epoch 348/1024\n",
      "9/9 - 0s - loss: 0.4157\n",
      "Epoch 349/1024\n",
      "9/9 - 0s - loss: 0.4033\n",
      "Epoch 350/1024\n",
      "9/9 - 0s - loss: 0.4080\n",
      "Epoch 351/1024\n",
      "9/9 - 0s - loss: 0.4145\n",
      "Epoch 352/1024\n",
      "9/9 - 0s - loss: 0.4065\n",
      "Epoch 353/1024\n",
      "9/9 - 0s - loss: 0.4092\n",
      "Epoch 354/1024\n",
      "9/9 - 0s - loss: 0.3992\n",
      "Epoch 355/1024\n",
      "9/9 - 0s - loss: 0.4088\n",
      "Epoch 356/1024\n",
      "9/9 - 0s - loss: 0.3987\n",
      "Epoch 357/1024\n",
      "9/9 - 0s - loss: 0.3989\n",
      "Epoch 358/1024\n",
      "9/9 - 0s - loss: 0.4156\n",
      "Epoch 359/1024\n",
      "9/9 - 0s - loss: 0.4099\n",
      "Epoch 360/1024\n",
      "9/9 - 0s - loss: 0.4075\n",
      "Epoch 361/1024\n",
      "9/9 - 0s - loss: 0.4017\n",
      "Epoch 362/1024\n",
      "9/9 - 0s - loss: 0.3946\n",
      "Epoch 363/1024\n",
      "9/9 - 0s - loss: 0.3973\n",
      "Epoch 364/1024\n",
      "9/9 - 0s - loss: 0.3981\n",
      "Epoch 365/1024\n",
      "9/9 - 0s - loss: 0.4082\n",
      "Epoch 366/1024\n",
      "9/9 - 0s - loss: 0.3952\n",
      "Epoch 367/1024\n",
      "9/9 - 0s - loss: 0.3947\n",
      "Epoch 368/1024\n",
      "9/9 - 0s - loss: 0.4025\n",
      "Epoch 369/1024\n",
      "9/9 - 0s - loss: 0.4066\n",
      "Epoch 370/1024\n",
      "9/9 - 0s - loss: 0.3961\n",
      "Epoch 371/1024\n",
      "9/9 - 0s - loss: 0.3980\n",
      "Epoch 372/1024\n",
      "9/9 - 0s - loss: 0.4036\n",
      "Epoch 373/1024\n",
      "9/9 - 0s - loss: 0.4115\n",
      "Epoch 374/1024\n",
      "9/9 - 0s - loss: 0.3974\n",
      "Epoch 375/1024\n",
      "9/9 - 0s - loss: 0.4013\n",
      "Epoch 376/1024\n",
      "9/9 - 0s - loss: 0.3962\n",
      "Epoch 377/1024\n",
      "9/9 - 0s - loss: 0.4040\n",
      "Epoch 378/1024\n",
      "9/9 - 0s - loss: 0.4063\n",
      "Epoch 379/1024\n",
      "9/9 - 0s - loss: 0.4028\n",
      "Epoch 380/1024\n",
      "9/9 - 0s - loss: 0.3963\n",
      "Epoch 381/1024\n",
      "9/9 - 0s - loss: 0.4095\n",
      "Epoch 382/1024\n",
      "9/9 - 0s - loss: 0.3890\n",
      "Epoch 383/1024\n",
      "9/9 - 0s - loss: 0.4024\n",
      "Epoch 384/1024\n",
      "9/9 - 0s - loss: 0.4019\n",
      "Epoch 385/1024\n",
      "9/9 - 0s - loss: 0.4068\n",
      "Epoch 386/1024\n",
      "9/9 - 0s - loss: 0.4077\n",
      "Epoch 387/1024\n",
      "9/9 - 0s - loss: 0.4050\n",
      "Epoch 388/1024\n",
      "9/9 - 0s - loss: 0.4020\n",
      "Epoch 389/1024\n",
      "9/9 - 0s - loss: 0.4083\n",
      "Epoch 390/1024\n",
      "9/9 - 0s - loss: 0.3938\n",
      "Epoch 391/1024\n",
      "9/9 - 0s - loss: 0.4031\n",
      "Epoch 392/1024\n",
      "9/9 - 0s - loss: 0.4069\n",
      "Epoch 393/1024\n",
      "9/9 - 0s - loss: 0.3859\n",
      "Epoch 394/1024\n",
      "9/9 - 0s - loss: 0.4006\n",
      "Epoch 395/1024\n",
      "9/9 - 0s - loss: 0.3955\n",
      "Epoch 396/1024\n",
      "9/9 - 0s - loss: 0.3927\n",
      "Epoch 397/1024\n",
      "9/9 - 0s - loss: 0.4043\n",
      "Epoch 398/1024\n",
      "9/9 - 0s - loss: 0.3875\n",
      "Epoch 399/1024\n",
      "9/9 - 0s - loss: 0.4041\n",
      "Epoch 400/1024\n",
      "9/9 - 0s - loss: 0.3947\n",
      "Epoch 401/1024\n",
      "9/9 - 0s - loss: 0.4009\n",
      "Epoch 402/1024\n",
      "9/9 - 0s - loss: 0.3974\n",
      "Epoch 403/1024\n",
      "9/9 - 0s - loss: 0.3900\n",
      "Epoch 404/1024\n",
      "9/9 - 0s - loss: 0.3903\n",
      "Epoch 405/1024\n",
      "9/9 - 0s - loss: 0.3884\n",
      "Epoch 406/1024\n",
      "9/9 - 0s - loss: 0.3875\n",
      "Epoch 407/1024\n",
      "9/9 - 0s - loss: 0.3913\n",
      "Epoch 408/1024\n",
      "9/9 - 0s - loss: 0.3989\n",
      "Epoch 409/1024\n",
      "9/9 - 0s - loss: 0.3962\n",
      "Epoch 410/1024\n",
      "9/9 - 0s - loss: 0.3951\n",
      "Epoch 411/1024\n",
      "9/9 - 0s - loss: 0.3951\n",
      "Epoch 412/1024\n",
      "9/9 - 0s - loss: 0.3909\n",
      "Epoch 413/1024\n",
      "9/9 - 0s - loss: 0.3967\n",
      "Epoch 414/1024\n",
      "9/9 - 0s - loss: 0.3783\n",
      "Epoch 415/1024\n",
      "9/9 - 0s - loss: 0.3909\n",
      "Epoch 416/1024\n",
      "9/9 - 0s - loss: 0.3928\n",
      "Epoch 417/1024\n",
      "9/9 - 0s - loss: 0.4002\n",
      "Epoch 418/1024\n",
      "9/9 - 0s - loss: 0.3994\n",
      "Epoch 419/1024\n",
      "9/9 - 0s - loss: 0.3887\n",
      "Epoch 420/1024\n",
      "9/9 - 0s - loss: 0.3887\n",
      "Epoch 421/1024\n",
      "9/9 - 0s - loss: 0.3919\n",
      "Epoch 422/1024\n",
      "9/9 - 0s - loss: 0.4009\n",
      "Epoch 423/1024\n",
      "9/9 - 0s - loss: 0.3886\n",
      "Epoch 424/1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 - 0s - loss: 0.3953\n",
      "Epoch 425/1024\n",
      "9/9 - 0s - loss: 0.3936\n",
      "Epoch 426/1024\n",
      "9/9 - 0s - loss: 0.3919\n",
      "Epoch 427/1024\n",
      "9/9 - 0s - loss: 0.3976\n",
      "Epoch 428/1024\n",
      "9/9 - 0s - loss: 0.3980\n",
      "Epoch 429/1024\n",
      "9/9 - 0s - loss: 0.3908\n",
      "Epoch 430/1024\n",
      "9/9 - 0s - loss: 0.3885\n",
      "Epoch 431/1024\n",
      "9/9 - 0s - loss: 0.3972\n",
      "Epoch 432/1024\n",
      "9/9 - 0s - loss: 0.3975\n",
      "Epoch 433/1024\n",
      "9/9 - 0s - loss: 0.3928\n",
      "Epoch 434/1024\n",
      "9/9 - 0s - loss: 0.3979\n",
      "Epoch 435/1024\n",
      "9/9 - 0s - loss: 0.3902\n",
      "Epoch 436/1024\n",
      "9/9 - 0s - loss: 0.3976\n",
      "Epoch 437/1024\n",
      "9/9 - 0s - loss: 0.4030\n",
      "Epoch 438/1024\n",
      "9/9 - 0s - loss: 0.3943\n",
      "Epoch 439/1024\n",
      "9/9 - 0s - loss: 0.3911\n",
      "Epoch 440/1024\n",
      "9/9 - 0s - loss: 0.3967\n",
      "Epoch 441/1024\n",
      "9/9 - 0s - loss: 0.3840\n",
      "Epoch 442/1024\n",
      "9/9 - 0s - loss: 0.3804\n",
      "Epoch 443/1024\n",
      "9/9 - 0s - loss: 0.3955\n",
      "Epoch 444/1024\n",
      "9/9 - 0s - loss: 0.3895\n",
      "Epoch 445/1024\n",
      "9/9 - 0s - loss: 0.3949\n",
      "Epoch 446/1024\n",
      "9/9 - 0s - loss: 0.3967\n",
      "Epoch 447/1024\n",
      "9/9 - 0s - loss: 0.3927\n",
      "Epoch 448/1024\n",
      "9/9 - 0s - loss: 0.3867\n",
      "Epoch 449/1024\n",
      "9/9 - 0s - loss: 0.3941\n",
      "Epoch 450/1024\n",
      "9/9 - 0s - loss: 0.3858\n",
      "Epoch 451/1024\n",
      "9/9 - 0s - loss: 0.3781\n",
      "Epoch 452/1024\n",
      "9/9 - 0s - loss: 0.3864\n",
      "Epoch 453/1024\n",
      "9/9 - 0s - loss: 0.3917\n",
      "Epoch 454/1024\n",
      "9/9 - 0s - loss: 0.3821\n",
      "Epoch 455/1024\n",
      "9/9 - 0s - loss: 0.3839\n",
      "Epoch 456/1024\n",
      "9/9 - 0s - loss: 0.3904\n",
      "Epoch 457/1024\n",
      "9/9 - 0s - loss: 0.3997\n",
      "Epoch 458/1024\n",
      "9/9 - 0s - loss: 0.3886\n",
      "Epoch 459/1024\n",
      "9/9 - 0s - loss: 0.4010\n",
      "Epoch 460/1024\n",
      "9/9 - 0s - loss: 0.3872\n",
      "Epoch 461/1024\n",
      "9/9 - 0s - loss: 0.3960\n",
      "Epoch 462/1024\n",
      "9/9 - 0s - loss: 0.3983\n",
      "Epoch 463/1024\n",
      "9/9 - 0s - loss: 0.3825\n",
      "Epoch 464/1024\n",
      "9/9 - 0s - loss: 0.3853\n",
      "Epoch 465/1024\n",
      "9/9 - 0s - loss: 0.3829\n",
      "Epoch 466/1024\n",
      "9/9 - 0s - loss: 0.3919\n",
      "Epoch 467/1024\n",
      "9/9 - 0s - loss: 0.3846\n",
      "Epoch 468/1024\n",
      "9/9 - 0s - loss: 0.3868\n",
      "Epoch 469/1024\n",
      "9/9 - 0s - loss: 0.3860\n",
      "Epoch 470/1024\n",
      "9/9 - 0s - loss: 0.3949\n",
      "Epoch 471/1024\n",
      "9/9 - 0s - loss: 0.3869\n",
      "Epoch 472/1024\n",
      "9/9 - 0s - loss: 0.3880\n",
      "Epoch 473/1024\n",
      "9/9 - 0s - loss: 0.3905\n",
      "Epoch 474/1024\n",
      "9/9 - 0s - loss: 0.3898\n",
      "Epoch 475/1024\n",
      "9/9 - 0s - loss: 0.3866\n",
      "Epoch 476/1024\n",
      "9/9 - 0s - loss: 0.3901\n",
      "Epoch 477/1024\n",
      "9/9 - 0s - loss: 0.3952\n",
      "Epoch 478/1024\n",
      "9/9 - 0s - loss: 0.3811\n",
      "Epoch 479/1024\n",
      "9/9 - 0s - loss: 0.3826\n",
      "Epoch 480/1024\n",
      "9/9 - 0s - loss: 0.3891\n",
      "Epoch 481/1024\n",
      "9/9 - 0s - loss: 0.3920\n",
      "Epoch 482/1024\n",
      "9/9 - 0s - loss: 0.3847\n",
      "Epoch 483/1024\n",
      "9/9 - 0s - loss: 0.3883\n",
      "Epoch 484/1024\n",
      "9/9 - 0s - loss: 0.3800\n",
      "Epoch 485/1024\n",
      "9/9 - 0s - loss: 0.3881\n",
      "Epoch 486/1024\n",
      "9/9 - 0s - loss: 0.3864\n",
      "Epoch 487/1024\n",
      "9/9 - 0s - loss: 0.3993\n",
      "Epoch 488/1024\n",
      "9/9 - 0s - loss: 0.3844\n",
      "Epoch 489/1024\n",
      "9/9 - 0s - loss: 0.3907\n",
      "Epoch 490/1024\n",
      "9/9 - 0s - loss: 0.3927\n",
      "Epoch 491/1024\n",
      "9/9 - 0s - loss: 0.3873\n",
      "Epoch 492/1024\n",
      "9/9 - 0s - loss: 0.3914\n",
      "Epoch 493/1024\n",
      "9/9 - 0s - loss: 0.3891\n",
      "Epoch 494/1024\n",
      "9/9 - 0s - loss: 0.3831\n",
      "Epoch 495/1024\n",
      "9/9 - 0s - loss: 0.3944\n",
      "Epoch 496/1024\n",
      "9/9 - 0s - loss: 0.3866\n",
      "Epoch 497/1024\n",
      "9/9 - 0s - loss: 0.3887\n",
      "Epoch 498/1024\n",
      "9/9 - 0s - loss: 0.3932\n",
      "Epoch 499/1024\n",
      "9/9 - 0s - loss: 0.3807\n",
      "Epoch 500/1024\n",
      "9/9 - 0s - loss: 0.3876\n",
      "Epoch 501/1024\n",
      "9/9 - 0s - loss: 0.3880\n",
      "Epoch 502/1024\n",
      "9/9 - 0s - loss: 0.3867\n",
      "Epoch 503/1024\n",
      "9/9 - 0s - loss: 0.3888\n",
      "Epoch 504/1024\n",
      "9/9 - 0s - loss: 0.3839\n",
      "Epoch 505/1024\n",
      "9/9 - 0s - loss: 0.3799\n",
      "Epoch 506/1024\n",
      "9/9 - 0s - loss: 0.3762\n",
      "Epoch 507/1024\n",
      "9/9 - 0s - loss: 0.3893\n",
      "Epoch 508/1024\n",
      "9/9 - 0s - loss: 0.3783\n",
      "Epoch 509/1024\n",
      "9/9 - 0s - loss: 0.3831\n",
      "Epoch 510/1024\n",
      "9/9 - 0s - loss: 0.3787\n",
      "Epoch 511/1024\n",
      "9/9 - 0s - loss: 0.3829\n",
      "Epoch 512/1024\n",
      "9/9 - 0s - loss: 0.4008\n",
      "Epoch 513/1024\n",
      "9/9 - 0s - loss: 0.3758\n",
      "Epoch 514/1024\n",
      "9/9 - 0s - loss: 0.3796\n",
      "Epoch 515/1024\n",
      "9/9 - 0s - loss: 0.3927\n",
      "Epoch 516/1024\n",
      "9/9 - 0s - loss: 0.3804\n",
      "Epoch 517/1024\n",
      "9/9 - 0s - loss: 0.3939\n",
      "Epoch 518/1024\n",
      "9/9 - 0s - loss: 0.3982\n",
      "Epoch 519/1024\n",
      "9/9 - 0s - loss: 0.3928\n",
      "Epoch 520/1024\n",
      "9/9 - 0s - loss: 0.3911\n",
      "Epoch 521/1024\n",
      "9/9 - 0s - loss: 0.3887\n",
      "Epoch 522/1024\n",
      "9/9 - 0s - loss: 0.3836\n",
      "Epoch 523/1024\n",
      "9/9 - 0s - loss: 0.3910\n",
      "Epoch 524/1024\n",
      "9/9 - 0s - loss: 0.3854\n",
      "Epoch 525/1024\n",
      "9/9 - 0s - loss: 0.3797\n",
      "Epoch 526/1024\n",
      "9/9 - 0s - loss: 0.3963\n",
      "Epoch 527/1024\n",
      "9/9 - 0s - loss: 0.3832\n",
      "Epoch 528/1024\n",
      "9/9 - 0s - loss: 0.3849\n",
      "Epoch 529/1024\n",
      "9/9 - 0s - loss: 0.3901\n",
      "Epoch 530/1024\n",
      "9/9 - 0s - loss: 0.3947\n",
      "Epoch 531/1024\n",
      "9/9 - 0s - loss: 0.3766\n",
      "Epoch 532/1024\n",
      "9/9 - 0s - loss: 0.3866\n",
      "Epoch 533/1024\n",
      "9/9 - 0s - loss: 0.3937\n",
      "Epoch 534/1024\n",
      "9/9 - 0s - loss: 0.3783\n",
      "Epoch 535/1024\n",
      "9/9 - 0s - loss: 0.3824\n",
      "Epoch 536/1024\n",
      "9/9 - 0s - loss: 0.3863\n",
      "Epoch 537/1024\n",
      "9/9 - 0s - loss: 0.3906\n",
      "Epoch 538/1024\n",
      "9/9 - 0s - loss: 0.3973\n",
      "Epoch 539/1024\n",
      "9/9 - 0s - loss: 0.3792\n",
      "Epoch 540/1024\n",
      "9/9 - 0s - loss: 0.3897\n",
      "Epoch 541/1024\n",
      "9/9 - 0s - loss: 0.3868\n",
      "Epoch 542/1024\n",
      "9/9 - 0s - loss: 0.3808\n",
      "Epoch 543/1024\n",
      "9/9 - 0s - loss: 0.3875\n",
      "Epoch 544/1024\n",
      "9/9 - 0s - loss: 0.3844\n",
      "Epoch 545/1024\n",
      "9/9 - 0s - loss: 0.3778\n",
      "Epoch 546/1024\n",
      "9/9 - 0s - loss: 0.3888\n",
      "Epoch 547/1024\n",
      "9/9 - 0s - loss: 0.3848\n",
      "Epoch 548/1024\n",
      "9/9 - 0s - loss: 0.3787\n",
      "Epoch 549/1024\n",
      "9/9 - 0s - loss: 0.3670\n",
      "Epoch 550/1024\n",
      "9/9 - 0s - loss: 0.3806\n",
      "Epoch 551/1024\n",
      "9/9 - 0s - loss: 0.3865\n",
      "Epoch 552/1024\n",
      "9/9 - 0s - loss: 0.3969\n",
      "Epoch 553/1024\n",
      "9/9 - 0s - loss: 0.3695\n",
      "Epoch 554/1024\n",
      "9/9 - 0s - loss: 0.3882\n",
      "Epoch 555/1024\n",
      "9/9 - 0s - loss: 0.3833\n",
      "Epoch 556/1024\n",
      "9/9 - 0s - loss: 0.3882\n",
      "Epoch 557/1024\n",
      "9/9 - 0s - loss: 0.3809\n",
      "Epoch 558/1024\n",
      "9/9 - 0s - loss: 0.3776\n",
      "Epoch 559/1024\n",
      "9/9 - 0s - loss: 0.3822\n",
      "Epoch 560/1024\n",
      "9/9 - 0s - loss: 0.3939\n",
      "Epoch 561/1024\n",
      "9/9 - 0s - loss: 0.3771\n",
      "Epoch 562/1024\n",
      "9/9 - 0s - loss: 0.3856\n",
      "Epoch 563/1024\n",
      "9/9 - 0s - loss: 0.3833\n",
      "Epoch 564/1024\n",
      "9/9 - 0s - loss: 0.3762\n",
      "Epoch 565/1024\n",
      "9/9 - 0s - loss: 0.3899\n",
      "Epoch 566/1024\n",
      "9/9 - 0s - loss: 0.3828\n",
      "Epoch 567/1024\n",
      "9/9 - 0s - loss: 0.3899\n",
      "Epoch 568/1024\n",
      "9/9 - 0s - loss: 0.3922\n",
      "Epoch 569/1024\n",
      "9/9 - 0s - loss: 0.3747\n",
      "Epoch 570/1024\n",
      "9/9 - 0s - loss: 0.3847\n",
      "Epoch 571/1024\n",
      "9/9 - 0s - loss: 0.3878\n",
      "Epoch 572/1024\n",
      "9/9 - 0s - loss: 0.3894\n",
      "Epoch 573/1024\n",
      "9/9 - 0s - loss: 0.3885\n",
      "Epoch 574/1024\n",
      "9/9 - 0s - loss: 0.3911\n",
      "Epoch 575/1024\n",
      "9/9 - 0s - loss: 0.3952\n",
      "Epoch 576/1024\n",
      "9/9 - 0s - loss: 0.3869\n",
      "Epoch 577/1024\n",
      "9/9 - 0s - loss: 0.3738\n",
      "Epoch 578/1024\n",
      "9/9 - 0s - loss: 0.3888\n",
      "Epoch 579/1024\n",
      "9/9 - 0s - loss: 0.3806\n",
      "Epoch 580/1024\n",
      "9/9 - 0s - loss: 0.3859\n",
      "Epoch 581/1024\n",
      "9/9 - 0s - loss: 0.3755\n",
      "Epoch 582/1024\n",
      "9/9 - 0s - loss: 0.3834\n",
      "Epoch 583/1024\n",
      "9/9 - 0s - loss: 0.3915\n",
      "Epoch 584/1024\n",
      "9/9 - 0s - loss: 0.3939\n",
      "Epoch 585/1024\n",
      "9/9 - 0s - loss: 0.3839\n",
      "Epoch 586/1024\n",
      "9/9 - 0s - loss: 0.3825\n",
      "Epoch 587/1024\n",
      "9/9 - 0s - loss: 0.3813\n",
      "Epoch 588/1024\n",
      "9/9 - 0s - loss: 0.3810\n",
      "Epoch 589/1024\n",
      "9/9 - 0s - loss: 0.3771\n",
      "Epoch 590/1024\n",
      "9/9 - 0s - loss: 0.3936\n",
      "Epoch 591/1024\n",
      "9/9 - 0s - loss: 0.3830\n",
      "Epoch 592/1024\n",
      "9/9 - 0s - loss: 0.3821\n",
      "Epoch 593/1024\n",
      "9/9 - 0s - loss: 0.3777\n",
      "Epoch 594/1024\n",
      "9/9 - 0s - loss: 0.3918\n",
      "Epoch 595/1024\n",
      "9/9 - 0s - loss: 0.3825\n",
      "Epoch 596/1024\n",
      "9/9 - 0s - loss: 0.3911\n",
      "Epoch 597/1024\n",
      "9/9 - 0s - loss: 0.3869\n",
      "Epoch 598/1024\n",
      "9/9 - 0s - loss: 0.3714\n",
      "Epoch 599/1024\n",
      "9/9 - 0s - loss: 0.3848\n",
      "Epoch 600/1024\n",
      "9/9 - 0s - loss: 0.3935\n",
      "Epoch 601/1024\n",
      "9/9 - 0s - loss: 0.3836\n",
      "Epoch 602/1024\n",
      "9/9 - 0s - loss: 0.3800\n",
      "Epoch 603/1024\n",
      "9/9 - 0s - loss: 0.3818\n",
      "Epoch 604/1024\n",
      "9/9 - 0s - loss: 0.3691\n",
      "Epoch 605/1024\n",
      "9/9 - 0s - loss: 0.3837\n",
      "Epoch 606/1024\n",
      "9/9 - 0s - loss: 0.3683\n",
      "Epoch 607/1024\n",
      "9/9 - 0s - loss: 0.3808\n",
      "Epoch 608/1024\n",
      "9/9 - 0s - loss: 0.3804\n",
      "Epoch 609/1024\n",
      "9/9 - 0s - loss: 0.3911\n",
      "Epoch 610/1024\n",
      "9/9 - 0s - loss: 0.3909\n",
      "Epoch 611/1024\n",
      "9/9 - 0s - loss: 0.3853\n",
      "Epoch 612/1024\n",
      "9/9 - 0s - loss: 0.3937\n",
      "Epoch 613/1024\n",
      "9/9 - 0s - loss: 0.3807\n",
      "Epoch 614/1024\n",
      "9/9 - 0s - loss: 0.3848\n",
      "Epoch 615/1024\n",
      "9/9 - 0s - loss: 0.3870\n",
      "Epoch 616/1024\n",
      "9/9 - 0s - loss: 0.3818\n",
      "Epoch 617/1024\n",
      "9/9 - 0s - loss: 0.3801\n",
      "Epoch 618/1024\n",
      "9/9 - 0s - loss: 0.3735\n",
      "Epoch 619/1024\n",
      "9/9 - 0s - loss: 0.3897\n",
      "Epoch 620/1024\n",
      "9/9 - 0s - loss: 0.3697\n",
      "Epoch 621/1024\n",
      "9/9 - 0s - loss: 0.3817\n",
      "Epoch 622/1024\n",
      "9/9 - 0s - loss: 0.3813\n",
      "Epoch 623/1024\n",
      "9/9 - 0s - loss: 0.3869\n",
      "Epoch 624/1024\n",
      "9/9 - 0s - loss: 0.3811\n",
      "Epoch 625/1024\n",
      "9/9 - 0s - loss: 0.3747\n",
      "Epoch 626/1024\n",
      "9/9 - 0s - loss: 0.3798\n",
      "Epoch 627/1024\n",
      "9/9 - 0s - loss: 0.3901\n",
      "Epoch 628/1024\n",
      "9/9 - 0s - loss: 0.3723\n",
      "Epoch 629/1024\n",
      "9/9 - 0s - loss: 0.3779\n",
      "Epoch 630/1024\n",
      "9/9 - 0s - loss: 0.3884\n",
      "Epoch 631/1024\n",
      "9/9 - 0s - loss: 0.3816\n",
      "Epoch 632/1024\n",
      "9/9 - 0s - loss: 0.3939\n",
      "Epoch 633/1024\n",
      "9/9 - 0s - loss: 0.3771\n",
      "Epoch 634/1024\n",
      "9/9 - 0s - loss: 0.3808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 635/1024\n",
      "9/9 - 0s - loss: 0.3848\n",
      "Epoch 636/1024\n",
      "9/9 - 0s - loss: 0.3784\n",
      "Epoch 637/1024\n",
      "9/9 - 0s - loss: 0.3773\n",
      "Epoch 638/1024\n",
      "9/9 - 0s - loss: 0.3864\n",
      "Epoch 639/1024\n",
      "9/9 - 0s - loss: 0.3830\n",
      "Epoch 640/1024\n",
      "9/9 - 0s - loss: 0.3766\n",
      "Epoch 641/1024\n",
      "9/9 - 0s - loss: 0.3881\n",
      "Epoch 642/1024\n",
      "9/9 - 0s - loss: 0.3799\n",
      "Epoch 643/1024\n",
      "9/9 - 0s - loss: 0.3746\n",
      "Epoch 644/1024\n",
      "9/9 - 0s - loss: 0.3841\n",
      "Epoch 645/1024\n",
      "9/9 - 0s - loss: 0.3718\n",
      "Epoch 646/1024\n",
      "9/9 - 0s - loss: 0.3787\n",
      "Epoch 647/1024\n",
      "9/9 - 0s - loss: 0.3765\n",
      "Epoch 648/1024\n",
      "9/9 - 0s - loss: 0.3831\n",
      "Epoch 649/1024\n",
      "9/9 - 0s - loss: 0.3729\n",
      "Epoch 650/1024\n",
      "9/9 - 0s - loss: 0.3875\n",
      "Epoch 651/1024\n",
      "9/9 - 0s - loss: 0.3807\n",
      "Epoch 652/1024\n",
      "9/9 - 0s - loss: 0.3818\n",
      "Epoch 653/1024\n",
      "9/9 - 0s - loss: 0.3841\n",
      "Epoch 654/1024\n",
      "9/9 - 0s - loss: 0.3742\n",
      "Epoch 655/1024\n",
      "9/9 - 0s - loss: 0.3811\n",
      "Epoch 656/1024\n",
      "9/9 - 0s - loss: 0.3900\n",
      "Epoch 657/1024\n",
      "9/9 - 0s - loss: 0.3959\n",
      "Epoch 658/1024\n",
      "9/9 - 0s - loss: 0.3911\n",
      "Epoch 659/1024\n",
      "9/9 - 0s - loss: 0.3914\n",
      "Epoch 660/1024\n",
      "9/9 - 0s - loss: 0.3760\n",
      "Epoch 661/1024\n",
      "9/9 - 0s - loss: 0.3923\n",
      "Epoch 662/1024\n",
      "9/9 - 0s - loss: 0.3748\n",
      "Epoch 663/1024\n",
      "9/9 - 0s - loss: 0.3739\n",
      "Epoch 664/1024\n",
      "9/9 - 0s - loss: 0.3721\n",
      "Epoch 665/1024\n",
      "9/9 - 0s - loss: 0.3910\n",
      "Epoch 666/1024\n",
      "9/9 - 0s - loss: 0.3686\n",
      "Epoch 667/1024\n",
      "9/9 - 0s - loss: 0.3916\n",
      "Epoch 668/1024\n",
      "9/9 - 0s - loss: 0.3739\n",
      "Epoch 669/1024\n",
      "9/9 - 0s - loss: 0.3860\n",
      "Epoch 670/1024\n",
      "9/9 - 0s - loss: 0.3737\n",
      "Epoch 671/1024\n",
      "9/9 - 0s - loss: 0.3834\n",
      "Epoch 672/1024\n",
      "9/9 - 0s - loss: 0.3948\n",
      "Epoch 673/1024\n",
      "9/9 - 0s - loss: 0.3939\n",
      "Epoch 674/1024\n",
      "9/9 - 0s - loss: 0.3940\n",
      "Epoch 675/1024\n",
      "9/9 - 0s - loss: 0.3767\n",
      "Epoch 676/1024\n",
      "9/9 - 0s - loss: 0.3920\n",
      "Epoch 677/1024\n",
      "9/9 - 0s - loss: 0.3892\n",
      "Epoch 678/1024\n",
      "9/9 - 0s - loss: 0.3875\n",
      "Epoch 679/1024\n",
      "9/9 - 0s - loss: 0.3724\n",
      "Epoch 680/1024\n",
      "9/9 - 0s - loss: 0.3929\n",
      "Epoch 681/1024\n",
      "9/9 - 0s - loss: 0.3789\n",
      "Epoch 682/1024\n",
      "9/9 - 0s - loss: 0.3864\n",
      "Epoch 683/1024\n",
      "9/9 - 0s - loss: 0.3774\n",
      "Epoch 684/1024\n",
      "9/9 - 0s - loss: 0.3918\n",
      "Epoch 685/1024\n",
      "9/9 - 0s - loss: 0.3832\n",
      "Epoch 686/1024\n",
      "9/9 - 0s - loss: 0.3905\n",
      "Epoch 687/1024\n",
      "9/9 - 0s - loss: 0.3857\n",
      "Epoch 688/1024\n",
      "9/9 - 0s - loss: 0.3801\n",
      "Epoch 689/1024\n",
      "9/9 - 0s - loss: 0.3847\n",
      "Epoch 690/1024\n",
      "9/9 - 0s - loss: 0.3750\n",
      "Epoch 691/1024\n",
      "9/9 - 0s - loss: 0.3741\n",
      "Epoch 692/1024\n",
      "9/9 - 0s - loss: 0.3752\n",
      "Epoch 693/1024\n",
      "9/9 - 0s - loss: 0.3790\n",
      "Epoch 694/1024\n",
      "9/9 - 0s - loss: 0.3845\n",
      "Epoch 695/1024\n",
      "9/9 - 0s - loss: 0.3847\n",
      "Epoch 696/1024\n",
      "9/9 - 0s - loss: 0.3771\n",
      "Epoch 697/1024\n",
      "9/9 - 0s - loss: 0.3943\n",
      "Epoch 698/1024\n",
      "9/9 - 0s - loss: 0.3842\n",
      "Epoch 699/1024\n",
      "9/9 - 0s - loss: 0.3790\n",
      "Epoch 700/1024\n",
      "9/9 - 0s - loss: 0.4027\n",
      "Epoch 701/1024\n",
      "9/9 - 0s - loss: 0.3915\n",
      "Epoch 702/1024\n",
      "9/9 - 0s - loss: 0.3787\n",
      "Epoch 703/1024\n",
      "9/9 - 0s - loss: 0.3814\n",
      "Epoch 704/1024\n",
      "9/9 - 0s - loss: 0.3877\n",
      "Epoch 705/1024\n",
      "9/9 - 0s - loss: 0.3888\n",
      "Epoch 706/1024\n",
      "9/9 - 0s - loss: 0.3748\n",
      "Epoch 707/1024\n",
      "9/9 - 0s - loss: 0.4021\n",
      "Epoch 708/1024\n",
      "9/9 - 0s - loss: 0.3774\n",
      "Epoch 709/1024\n",
      "9/9 - 0s - loss: 0.3887\n",
      "Epoch 710/1024\n",
      "9/9 - 0s - loss: 0.3763\n",
      "Epoch 711/1024\n",
      "9/9 - 0s - loss: 0.3875\n",
      "Epoch 712/1024\n",
      "9/9 - 0s - loss: 0.3727\n",
      "Epoch 713/1024\n",
      "9/9 - 0s - loss: 0.3889\n",
      "Epoch 714/1024\n",
      "9/9 - 0s - loss: 0.3737\n",
      "Epoch 715/1024\n",
      "9/9 - 0s - loss: 0.4005\n",
      "Epoch 716/1024\n",
      "9/9 - 0s - loss: 0.3884\n",
      "Epoch 717/1024\n",
      "9/9 - 0s - loss: 0.3898\n",
      "Epoch 718/1024\n",
      "9/9 - 0s - loss: 0.3847\n",
      "Epoch 719/1024\n",
      "9/9 - 0s - loss: 0.3705\n",
      "Epoch 720/1024\n",
      "9/9 - 0s - loss: 0.3818\n",
      "Epoch 721/1024\n",
      "9/9 - 0s - loss: 0.3745\n",
      "Epoch 722/1024\n",
      "9/9 - 0s - loss: 0.3808\n",
      "Epoch 723/1024\n",
      "9/9 - 0s - loss: 0.3813\n",
      "Epoch 724/1024\n",
      "9/9 - 0s - loss: 0.3934\n",
      "Epoch 725/1024\n",
      "9/9 - 0s - loss: 0.3728\n",
      "Epoch 726/1024\n",
      "9/9 - 0s - loss: 0.3954\n",
      "Epoch 727/1024\n",
      "9/9 - 0s - loss: 0.3745\n",
      "Epoch 728/1024\n",
      "9/9 - 0s - loss: 0.3824\n",
      "Epoch 729/1024\n",
      "9/9 - 0s - loss: 0.3774\n",
      "Epoch 730/1024\n",
      "9/9 - 0s - loss: 0.3839\n",
      "Epoch 731/1024\n",
      "9/9 - 0s - loss: 0.3768\n",
      "Epoch 732/1024\n",
      "9/9 - 0s - loss: 0.3866\n",
      "Epoch 733/1024\n",
      "9/9 - 0s - loss: 0.3774\n",
      "Epoch 734/1024\n",
      "9/9 - 0s - loss: 0.3828\n",
      "Epoch 735/1024\n",
      "9/9 - 0s - loss: 0.3949\n",
      "Epoch 736/1024\n",
      "9/9 - 0s - loss: 0.3864\n",
      "Epoch 737/1024\n",
      "9/9 - 0s - loss: 0.3873\n",
      "Epoch 738/1024\n",
      "9/9 - 0s - loss: 0.3856\n",
      "Epoch 739/1024\n",
      "9/9 - 0s - loss: 0.3832\n",
      "Epoch 740/1024\n",
      "9/9 - 0s - loss: 0.3792\n",
      "Epoch 741/1024\n",
      "9/9 - 0s - loss: 0.3871\n",
      "Epoch 742/1024\n",
      "9/9 - 0s - loss: 0.3878\n",
      "Epoch 743/1024\n",
      "9/9 - 0s - loss: 0.3800\n",
      "Epoch 744/1024\n",
      "9/9 - 0s - loss: 0.3860\n",
      "Epoch 745/1024\n",
      "9/9 - 0s - loss: 0.3806\n",
      "Epoch 746/1024\n",
      "9/9 - 0s - loss: 0.3767\n",
      "Epoch 747/1024\n",
      "9/9 - 0s - loss: 0.3799\n",
      "Epoch 748/1024\n",
      "9/9 - 0s - loss: 0.3973\n",
      "Epoch 749/1024\n",
      "9/9 - 0s - loss: 0.3752\n",
      "Epoch 750/1024\n",
      "9/9 - 0s - loss: 0.3852\n",
      "Epoch 751/1024\n",
      "9/9 - 0s - loss: 0.3928\n",
      "Epoch 752/1024\n",
      "9/9 - 0s - loss: 0.3716\n",
      "Epoch 753/1024\n",
      "9/9 - 0s - loss: 0.3771\n",
      "Epoch 754/1024\n",
      "9/9 - 0s - loss: 0.3899\n",
      "Epoch 755/1024\n",
      "9/9 - 0s - loss: 0.3994\n",
      "Epoch 756/1024\n",
      "9/9 - 0s - loss: 0.3931\n",
      "Epoch 757/1024\n",
      "9/9 - 0s - loss: 0.3849\n",
      "Epoch 758/1024\n",
      "9/9 - 0s - loss: 0.3830\n",
      "Epoch 759/1024\n",
      "9/9 - 0s - loss: 0.3815\n",
      "Epoch 760/1024\n",
      "9/9 - 0s - loss: 0.4000\n",
      "Epoch 761/1024\n",
      "9/9 - 0s - loss: 0.3831\n",
      "Epoch 762/1024\n",
      "9/9 - 0s - loss: 0.3908\n",
      "Epoch 763/1024\n",
      "9/9 - 0s - loss: 0.3665\n",
      "Epoch 764/1024\n",
      "9/9 - 0s - loss: 0.3794\n",
      "Epoch 765/1024\n",
      "9/9 - 0s - loss: 0.3836\n",
      "Epoch 766/1024\n",
      "9/9 - 0s - loss: 0.3798\n",
      "Epoch 767/1024\n",
      "9/9 - 0s - loss: 0.3832\n",
      "Epoch 768/1024\n",
      "9/9 - 0s - loss: 0.3836\n",
      "Epoch 769/1024\n",
      "9/9 - 0s - loss: 0.3793\n",
      "Epoch 770/1024\n",
      "9/9 - 0s - loss: 0.3884\n",
      "Epoch 771/1024\n",
      "9/9 - 0s - loss: 0.3939\n",
      "Epoch 772/1024\n",
      "9/9 - 0s - loss: 0.3706\n",
      "Epoch 773/1024\n",
      "9/9 - 0s - loss: 0.3798\n",
      "Epoch 774/1024\n",
      "9/9 - 0s - loss: 0.3848\n",
      "Epoch 775/1024\n",
      "9/9 - 0s - loss: 0.3760\n",
      "Epoch 776/1024\n",
      "9/9 - 0s - loss: 0.3935\n",
      "Epoch 777/1024\n",
      "9/9 - 0s - loss: 0.3792\n",
      "Epoch 778/1024\n",
      "9/9 - 0s - loss: 0.3870\n",
      "Epoch 779/1024\n",
      "9/9 - 0s - loss: 0.3817\n",
      "Epoch 780/1024\n",
      "9/9 - 0s - loss: 0.3886\n",
      "Epoch 781/1024\n",
      "9/9 - 0s - loss: 0.3921\n",
      "Epoch 782/1024\n",
      "9/9 - 0s - loss: 0.3796\n",
      "Epoch 783/1024\n",
      "9/9 - 0s - loss: 0.3683\n",
      "Epoch 784/1024\n",
      "9/9 - 0s - loss: 0.3923\n",
      "Epoch 785/1024\n",
      "9/9 - 0s - loss: 0.3791\n",
      "Epoch 786/1024\n",
      "9/9 - 0s - loss: 0.4002\n",
      "Epoch 787/1024\n",
      "9/9 - 0s - loss: 0.3831\n",
      "Epoch 788/1024\n",
      "9/9 - 0s - loss: 0.3790\n",
      "Epoch 789/1024\n",
      "9/9 - 0s - loss: 0.3921\n",
      "Epoch 790/1024\n",
      "9/9 - 0s - loss: 0.3916\n",
      "Epoch 791/1024\n",
      "9/9 - 0s - loss: 0.3864\n",
      "Epoch 792/1024\n",
      "9/9 - 0s - loss: 0.3814\n",
      "Epoch 793/1024\n",
      "9/9 - 0s - loss: 0.3759\n",
      "Epoch 794/1024\n",
      "9/9 - 0s - loss: 0.3817\n",
      "Epoch 795/1024\n",
      "9/9 - 0s - loss: 0.3825\n",
      "Epoch 796/1024\n",
      "9/9 - 0s - loss: 0.3778\n",
      "Epoch 797/1024\n",
      "9/9 - 0s - loss: 0.3841\n",
      "Epoch 798/1024\n",
      "9/9 - 0s - loss: 0.3950\n",
      "Epoch 799/1024\n",
      "9/9 - 0s - loss: 0.3811\n",
      "Epoch 800/1024\n",
      "9/9 - 0s - loss: 0.3904\n",
      "Epoch 801/1024\n",
      "9/9 - 0s - loss: 0.3857\n",
      "Epoch 802/1024\n",
      "9/9 - 0s - loss: 0.3872\n",
      "Epoch 803/1024\n",
      "9/9 - 0s - loss: 0.3809\n",
      "Epoch 804/1024\n",
      "9/9 - 0s - loss: 0.3896\n",
      "Epoch 805/1024\n",
      "9/9 - 0s - loss: 0.3893\n",
      "Epoch 806/1024\n",
      "9/9 - 0s - loss: 0.3892\n",
      "Epoch 807/1024\n",
      "9/9 - 0s - loss: 0.3822\n",
      "Epoch 808/1024\n",
      "9/9 - 0s - loss: 0.3927\n",
      "Epoch 809/1024\n",
      "9/9 - 0s - loss: 0.3891\n",
      "Epoch 810/1024\n",
      "9/9 - 0s - loss: 0.3888\n",
      "Epoch 811/1024\n",
      "9/9 - 0s - loss: 0.3889\n",
      "Epoch 812/1024\n",
      "9/9 - 0s - loss: 0.4038\n",
      "Epoch 813/1024\n",
      "9/9 - 0s - loss: 0.3920\n",
      "Epoch 814/1024\n",
      "9/9 - 0s - loss: 0.3976\n",
      "Epoch 815/1024\n",
      "9/9 - 0s - loss: 0.3801\n",
      "Epoch 816/1024\n",
      "9/9 - 0s - loss: 0.3845\n",
      "Epoch 817/1024\n",
      "9/9 - 0s - loss: 0.3859\n",
      "Epoch 818/1024\n",
      "9/9 - 0s - loss: 0.3865\n",
      "Epoch 819/1024\n",
      "9/9 - 0s - loss: 0.3794\n",
      "Epoch 820/1024\n",
      "9/9 - 0s - loss: 0.3899\n",
      "Epoch 821/1024\n",
      "9/9 - 0s - loss: 0.3793\n",
      "Epoch 822/1024\n",
      "9/9 - 0s - loss: 0.3810\n",
      "Epoch 823/1024\n",
      "9/9 - 0s - loss: 0.3761\n",
      "Epoch 824/1024\n",
      "9/9 - 0s - loss: 0.3870\n",
      "Epoch 825/1024\n",
      "9/9 - 0s - loss: 0.3804\n",
      "Epoch 826/1024\n",
      "9/9 - 0s - loss: 0.3896\n",
      "Epoch 827/1024\n",
      "9/9 - 0s - loss: 0.3901\n",
      "Epoch 828/1024\n",
      "9/9 - 0s - loss: 0.3826\n",
      "Epoch 829/1024\n",
      "9/9 - 0s - loss: 0.3862\n",
      "Epoch 830/1024\n",
      "9/9 - 0s - loss: 0.3764\n",
      "Epoch 831/1024\n",
      "9/9 - 0s - loss: 0.3924\n",
      "Epoch 832/1024\n",
      "9/9 - 0s - loss: 0.4020\n",
      "Epoch 833/1024\n",
      "9/9 - 0s - loss: 0.3863\n",
      "Epoch 834/1024\n",
      "9/9 - 0s - loss: 0.3762\n",
      "Epoch 835/1024\n",
      "9/9 - 0s - loss: 0.3971\n",
      "Epoch 836/1024\n",
      "9/9 - 0s - loss: 0.3877\n",
      "Epoch 837/1024\n",
      "9/9 - 0s - loss: 0.3863\n",
      "Epoch 838/1024\n",
      "9/9 - 0s - loss: 0.3748\n",
      "Epoch 839/1024\n",
      "9/9 - 0s - loss: 0.4026\n",
      "Epoch 840/1024\n",
      "9/9 - 0s - loss: 0.3968\n",
      "Epoch 841/1024\n",
      "9/9 - 0s - loss: 0.3760\n",
      "Epoch 842/1024\n",
      "9/9 - 0s - loss: 0.3839\n",
      "Epoch 843/1024\n",
      "9/9 - 0s - loss: 0.3699\n",
      "Epoch 844/1024\n",
      "9/9 - 0s - loss: 0.3888\n",
      "Epoch 845/1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 - 0s - loss: 0.3790\n",
      "Epoch 846/1024\n",
      "9/9 - 0s - loss: 0.3844\n",
      "Epoch 847/1024\n",
      "9/9 - 0s - loss: 0.3839\n",
      "Epoch 848/1024\n",
      "9/9 - 0s - loss: 0.3850\n",
      "Epoch 849/1024\n",
      "9/9 - 0s - loss: 0.3808\n",
      "Epoch 850/1024\n",
      "9/9 - 0s - loss: 0.3760\n",
      "Epoch 851/1024\n",
      "9/9 - 0s - loss: 0.3934\n",
      "Epoch 852/1024\n",
      "9/9 - 0s - loss: 0.3778\n",
      "Epoch 853/1024\n",
      "9/9 - 0s - loss: 0.3858\n",
      "Epoch 854/1024\n",
      "9/9 - 0s - loss: 0.3847\n",
      "Epoch 855/1024\n",
      "9/9 - 0s - loss: 0.3922\n",
      "Epoch 856/1024\n",
      "9/9 - 0s - loss: 0.3893\n",
      "Epoch 857/1024\n",
      "9/9 - 0s - loss: 0.3939\n",
      "Epoch 858/1024\n",
      "9/9 - 0s - loss: 0.3946\n",
      "Epoch 859/1024\n",
      "9/9 - 0s - loss: 0.3937\n",
      "Epoch 860/1024\n",
      "9/9 - 0s - loss: 0.3880\n",
      "Epoch 861/1024\n",
      "9/9 - 0s - loss: 0.3873\n",
      "Epoch 862/1024\n",
      "9/9 - 0s - loss: 0.3848\n",
      "Epoch 863/1024\n",
      "9/9 - 0s - loss: 0.3833\n",
      "Epoch 864/1024\n",
      "9/9 - 0s - loss: 0.3901\n",
      "Epoch 865/1024\n",
      "9/9 - 0s - loss: 0.3837\n",
      "Epoch 866/1024\n",
      "9/9 - 0s - loss: 0.3685\n",
      "Epoch 867/1024\n",
      "9/9 - 0s - loss: 0.3826\n",
      "Epoch 868/1024\n",
      "9/9 - 0s - loss: 0.3792\n",
      "Epoch 869/1024\n",
      "9/9 - 0s - loss: 0.3825\n",
      "Epoch 870/1024\n",
      "9/9 - 0s - loss: 0.3911\n",
      "Epoch 871/1024\n",
      "9/9 - 0s - loss: 0.3820\n",
      "Epoch 872/1024\n",
      "9/9 - 0s - loss: 0.3974\n",
      "Epoch 873/1024\n",
      "9/9 - 0s - loss: 0.3849\n",
      "Epoch 874/1024\n",
      "9/9 - 0s - loss: 0.3820\n",
      "Epoch 875/1024\n",
      "9/9 - 0s - loss: 0.3863\n",
      "Epoch 876/1024\n",
      "9/9 - 0s - loss: 0.3731\n",
      "Epoch 877/1024\n",
      "9/9 - 0s - loss: 0.3898\n",
      "Epoch 878/1024\n",
      "9/9 - 0s - loss: 0.3913\n",
      "Epoch 879/1024\n",
      "9/9 - 0s - loss: 0.3918\n",
      "Epoch 880/1024\n",
      "9/9 - 0s - loss: 0.3865\n",
      "Epoch 881/1024\n",
      "9/9 - 0s - loss: 0.3760\n",
      "Epoch 882/1024\n",
      "9/9 - 0s - loss: 0.3939\n",
      "Epoch 883/1024\n",
      "9/9 - 0s - loss: 0.3879\n",
      "Epoch 884/1024\n",
      "9/9 - 0s - loss: 0.3955\n",
      "Epoch 885/1024\n",
      "9/9 - 0s - loss: 0.3863\n",
      "Epoch 886/1024\n",
      "9/9 - 0s - loss: 0.3982\n",
      "Epoch 887/1024\n",
      "9/9 - 0s - loss: 0.3849\n",
      "Epoch 888/1024\n",
      "9/9 - 0s - loss: 0.3844\n",
      "Epoch 889/1024\n",
      "9/9 - 0s - loss: 0.3755\n",
      "Epoch 890/1024\n",
      "9/9 - 0s - loss: 0.3780\n",
      "Epoch 891/1024\n",
      "9/9 - 0s - loss: 0.3902\n",
      "Epoch 892/1024\n",
      "9/9 - 0s - loss: 0.3938\n",
      "Epoch 893/1024\n",
      "9/9 - 0s - loss: 0.3765\n",
      "Epoch 894/1024\n",
      "9/9 - 0s - loss: 0.3867\n",
      "Epoch 895/1024\n",
      "9/9 - 0s - loss: 0.3951\n",
      "Epoch 896/1024\n",
      "9/9 - 0s - loss: 0.3928\n",
      "Epoch 897/1024\n",
      "9/9 - 0s - loss: 0.3951\n",
      "Epoch 898/1024\n",
      "9/9 - 0s - loss: 0.3896\n",
      "Epoch 899/1024\n",
      "9/9 - 0s - loss: 0.3915\n",
      "Epoch 900/1024\n",
      "9/9 - 0s - loss: 0.3831\n",
      "Epoch 901/1024\n",
      "9/9 - 0s - loss: 0.3833\n",
      "Epoch 902/1024\n",
      "9/9 - 0s - loss: 0.3942\n",
      "Epoch 903/1024\n",
      "9/9 - 0s - loss: 0.3810\n",
      "Epoch 904/1024\n",
      "9/9 - 0s - loss: 0.3955\n",
      "Epoch 905/1024\n",
      "9/9 - 0s - loss: 0.3810\n",
      "Epoch 906/1024\n",
      "9/9 - 0s - loss: 0.3872\n",
      "Epoch 907/1024\n",
      "9/9 - 0s - loss: 0.3794\n",
      "Epoch 908/1024\n",
      "9/9 - 0s - loss: 0.3918\n",
      "Epoch 909/1024\n",
      "9/9 - 0s - loss: 0.3867\n",
      "Epoch 910/1024\n",
      "9/9 - 0s - loss: 0.3963\n",
      "Epoch 911/1024\n",
      "9/9 - 0s - loss: 0.3885\n",
      "Epoch 912/1024\n",
      "9/9 - 0s - loss: 0.3940\n",
      "Epoch 913/1024\n",
      "9/9 - 0s - loss: 0.3900\n",
      "Epoch 914/1024\n",
      "9/9 - 0s - loss: 0.3969\n",
      "Epoch 915/1024\n",
      "9/9 - 0s - loss: 0.3918\n",
      "Epoch 916/1024\n",
      "9/9 - 0s - loss: 0.3875\n",
      "Epoch 917/1024\n",
      "9/9 - 0s - loss: 0.3847\n",
      "Epoch 918/1024\n",
      "9/9 - 0s - loss: 0.3969\n",
      "Epoch 919/1024\n",
      "9/9 - 0s - loss: 0.3908\n",
      "Epoch 920/1024\n",
      "9/9 - 0s - loss: 0.3899\n",
      "Epoch 921/1024\n",
      "9/9 - 0s - loss: 0.3878\n",
      "Epoch 922/1024\n",
      "9/9 - 0s - loss: 0.4089\n",
      "Epoch 923/1024\n",
      "9/9 - 0s - loss: 0.3951\n",
      "Epoch 924/1024\n",
      "9/9 - 0s - loss: 0.4015\n",
      "Epoch 925/1024\n",
      "9/9 - 0s - loss: 0.3888\n",
      "Epoch 926/1024\n",
      "9/9 - 0s - loss: 0.3864\n",
      "Epoch 927/1024\n",
      "9/9 - 0s - loss: 0.3853\n",
      "Epoch 928/1024\n",
      "9/9 - 0s - loss: 0.3845\n",
      "Epoch 929/1024\n",
      "9/9 - 0s - loss: 0.3977\n",
      "Epoch 930/1024\n",
      "9/9 - 0s - loss: 0.3913\n",
      "Epoch 931/1024\n",
      "9/9 - 0s - loss: 0.3993\n",
      "Epoch 932/1024\n",
      "9/9 - 0s - loss: 0.3755\n",
      "Epoch 933/1024\n",
      "9/9 - 0s - loss: 0.3919\n",
      "Epoch 934/1024\n",
      "9/9 - 0s - loss: 0.3913\n",
      "Epoch 935/1024\n",
      "9/9 - 0s - loss: 0.3943\n",
      "Epoch 936/1024\n",
      "9/9 - 0s - loss: 0.3978\n",
      "Epoch 937/1024\n",
      "9/9 - 0s - loss: 0.3971\n",
      "Epoch 938/1024\n",
      "9/9 - 0s - loss: 0.3916\n",
      "Epoch 939/1024\n",
      "9/9 - 0s - loss: 0.3758\n",
      "Epoch 940/1024\n",
      "9/9 - 0s - loss: 0.4123\n",
      "Epoch 941/1024\n",
      "9/9 - 0s - loss: 0.3815\n",
      "Epoch 942/1024\n",
      "9/9 - 0s - loss: 0.3790\n",
      "Epoch 943/1024\n",
      "9/9 - 0s - loss: 0.3867\n",
      "Epoch 944/1024\n",
      "9/9 - 0s - loss: 0.3832\n",
      "Epoch 945/1024\n",
      "9/9 - 0s - loss: 0.3995\n",
      "Epoch 946/1024\n",
      "9/9 - 0s - loss: 0.3915\n",
      "Epoch 947/1024\n",
      "9/9 - 0s - loss: 0.3806\n",
      "Epoch 948/1024\n",
      "9/9 - 0s - loss: 0.4178\n",
      "Epoch 949/1024\n",
      "9/9 - 0s - loss: 0.3835\n",
      "Epoch 950/1024\n",
      "9/9 - 0s - loss: 0.3839\n",
      "Epoch 951/1024\n",
      "9/9 - 0s - loss: 0.3766\n",
      "Epoch 952/1024\n",
      "9/9 - 0s - loss: 0.3820\n",
      "Epoch 953/1024\n",
      "9/9 - 0s - loss: 0.3923\n",
      "Epoch 954/1024\n",
      "9/9 - 0s - loss: 0.3879\n",
      "Epoch 955/1024\n",
      "9/9 - 0s - loss: 0.3915\n",
      "Epoch 956/1024\n",
      "9/9 - 0s - loss: 0.4019\n",
      "Epoch 957/1024\n",
      "9/9 - 0s - loss: 0.3901\n",
      "Epoch 958/1024\n",
      "9/9 - 0s - loss: 0.4032\n",
      "Epoch 959/1024\n",
      "9/9 - 0s - loss: 0.3841\n",
      "Epoch 960/1024\n",
      "9/9 - 0s - loss: 0.3923\n",
      "Epoch 961/1024\n",
      "9/9 - 0s - loss: 0.3947\n",
      "Epoch 962/1024\n",
      "9/9 - 0s - loss: 0.3820\n",
      "Epoch 963/1024\n",
      "9/9 - 0s - loss: 0.3998\n",
      "Epoch 964/1024\n",
      "9/9 - 0s - loss: 0.3795\n",
      "Epoch 965/1024\n",
      "9/9 - 0s - loss: 0.3859\n",
      "Epoch 966/1024\n",
      "9/9 - 0s - loss: 0.4011\n",
      "Epoch 967/1024\n",
      "9/9 - 0s - loss: 0.3950\n",
      "Epoch 968/1024\n",
      "9/9 - 0s - loss: 0.3880\n",
      "Epoch 969/1024\n",
      "9/9 - 0s - loss: 0.3996\n",
      "Epoch 970/1024\n",
      "9/9 - 0s - loss: 0.3933\n",
      "Epoch 971/1024\n",
      "9/9 - 0s - loss: 0.4013\n",
      "Epoch 972/1024\n",
      "9/9 - 0s - loss: 0.3871\n",
      "Epoch 973/1024\n",
      "9/9 - 0s - loss: 0.4042\n",
      "Epoch 974/1024\n",
      "9/9 - 0s - loss: 0.3933\n",
      "Epoch 975/1024\n",
      "9/9 - 0s - loss: 0.4051\n",
      "Epoch 976/1024\n",
      "9/9 - 0s - loss: 0.3890\n",
      "Epoch 977/1024\n",
      "9/9 - 0s - loss: 0.3934\n",
      "Epoch 978/1024\n",
      "9/9 - 0s - loss: 0.3960\n",
      "Epoch 979/1024\n",
      "9/9 - 0s - loss: 0.3943\n",
      "Epoch 980/1024\n",
      "9/9 - 0s - loss: 0.4034\n",
      "Epoch 981/1024\n",
      "9/9 - 0s - loss: 0.3907\n",
      "Epoch 982/1024\n",
      "9/9 - 0s - loss: 0.3846\n",
      "Epoch 983/1024\n",
      "9/9 - 0s - loss: 0.3902\n",
      "Epoch 984/1024\n",
      "9/9 - 0s - loss: 0.3914\n",
      "Epoch 985/1024\n",
      "9/9 - 0s - loss: 0.4012\n",
      "Epoch 986/1024\n",
      "9/9 - 0s - loss: 0.4075\n",
      "Epoch 987/1024\n",
      "9/9 - 0s - loss: 0.3870\n",
      "Epoch 988/1024\n",
      "9/9 - 0s - loss: 0.3865\n",
      "Epoch 989/1024\n",
      "9/9 - 0s - loss: 0.3907\n",
      "Epoch 990/1024\n",
      "9/9 - 0s - loss: 0.3798\n",
      "Epoch 991/1024\n",
      "9/9 - 0s - loss: 0.3982\n",
      "Epoch 992/1024\n",
      "9/9 - 0s - loss: 0.3939\n",
      "Epoch 993/1024\n",
      "9/9 - 0s - loss: 0.3976\n",
      "Epoch 994/1024\n",
      "9/9 - 0s - loss: 0.3891\n",
      "Epoch 995/1024\n",
      "9/9 - 0s - loss: 0.3856\n",
      "Epoch 996/1024\n",
      "9/9 - 0s - loss: 0.4012\n",
      "Epoch 997/1024\n",
      "9/9 - 0s - loss: 0.3954\n",
      "Epoch 998/1024\n",
      "9/9 - 0s - loss: 0.4081\n",
      "Epoch 999/1024\n",
      "9/9 - 0s - loss: 0.3899\n",
      "Epoch 1000/1024\n",
      "9/9 - 0s - loss: 0.4047\n",
      "Epoch 1001/1024\n",
      "9/9 - 0s - loss: 0.3865\n",
      "Epoch 1002/1024\n",
      "9/9 - 0s - loss: 0.4103\n",
      "Epoch 1003/1024\n",
      "9/9 - 0s - loss: 0.4081\n",
      "Epoch 1004/1024\n",
      "9/9 - 0s - loss: 0.4044\n",
      "Epoch 1005/1024\n",
      "9/9 - 0s - loss: 0.3972\n",
      "Epoch 1006/1024\n",
      "9/9 - 0s - loss: 0.4010\n",
      "Epoch 1007/1024\n",
      "9/9 - 0s - loss: 0.4040\n",
      "Epoch 1008/1024\n",
      "9/9 - 0s - loss: 0.3838\n",
      "Epoch 1009/1024\n",
      "9/9 - 0s - loss: 0.3995\n",
      "Epoch 1010/1024\n",
      "9/9 - 0s - loss: 0.4004\n",
      "Epoch 1011/1024\n",
      "9/9 - 0s - loss: 0.4037\n",
      "Epoch 1012/1024\n",
      "9/9 - 0s - loss: 0.3780\n",
      "Epoch 1013/1024\n",
      "9/9 - 0s - loss: 0.3949\n",
      "Epoch 1014/1024\n",
      "9/9 - 0s - loss: 0.3850\n",
      "Epoch 1015/1024\n",
      "9/9 - 0s - loss: 0.4058\n",
      "Epoch 1016/1024\n",
      "9/9 - 0s - loss: 0.4042\n",
      "Epoch 1017/1024\n",
      "9/9 - 0s - loss: 0.4012\n",
      "Epoch 1018/1024\n",
      "9/9 - 0s - loss: 0.4020\n",
      "Epoch 1019/1024\n",
      "9/9 - 0s - loss: 0.3992\n",
      "Epoch 1020/1024\n",
      "9/9 - 0s - loss: 0.3944\n",
      "Epoch 1021/1024\n",
      "9/9 - 0s - loss: 0.3943\n",
      "Epoch 1022/1024\n",
      "9/9 - 0s - loss: 0.3866\n",
      "Epoch 1023/1024\n",
      "9/9 - 0s - loss: 0.3805\n",
      "Epoch 1024/1024\n",
      "9/9 - 0s - loss: 0.3862\n"
     ]
    }
   ],
   "source": [
    "tokens = np.array([x.split() for x in train_subset[\"title\"]])\n",
    "w2v_custom = Word2VecModel()\n",
    "w2v_custom.fit(tokens, epochs=1024, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'trained_word2vec.wv.vectors.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-da1e868d71f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trained_word2vec\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/git/word2vec/word2vec/classifier.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, word2vec_weights)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2vec_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mknn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2vec_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_average_word_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, rethrow, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1937\u001b[0m         \"\"\"\n\u001b[1;32m   1938\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1939\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1940\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1941\u001b[0m                 \u001b[0mrethrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, fname, mmap)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_specials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_lifecycle_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loaded\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m_load_specials\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1953\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_load_specials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1954\u001b[0m         \u001b[0;34m\"\"\"Handle special requirements of `.load()` protocol, usually up-converting older versions.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1955\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_specials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1956\u001b[0m         \u001b[0;31m# for backward compatibility, add/rearrange properties from prior versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1957\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ns_exponent'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36m_load_specials\u001b[0;34m(self, fname, mmap, compress, subname)\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loading %s recursively from %s.* with mmap=%s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrib\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mignore_deprecation_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m                 \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrib\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_specials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mattrib\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__numpys'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m_load_specials\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_load_specials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;34m\"\"\"Handle special requirements of `.load()` protocol, usually up-converting older versions.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKeyedVectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_specials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'doctags'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_upconvert_old_d2vkv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36m_load_specials\u001b[0;34m(self, fname, mmap, compress, subname)\u001b[0m\n\u001b[1;32m    527\u001b[0m                 \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrib\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m                 \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrib\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmmap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mignore_deprecation_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'trained_word2vec.wv.vectors.npy'"
     ]
    }
   ],
   "source": [
    "c = Classifier(\"trained_word2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.fit(train_subset[\"title\"], train_subset[\"categories\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c.predict(train_subset[\"title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Classifier(\"trained_word2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df_data.sample(frac=1).reset_index(drop=True)\n",
    "classes = np.array(df_data[\"categories\"])\n",
    "classes = classes[:10000]\n",
    "titles = np.array(df_data[\"title\"])\n",
    "titles = titles[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "i = 0\n",
    "for train_index, test_index in kf.split(titles):\n",
    "    print(\"FOLD \", i)\n",
    "    X_train, X_test = titles[train_index], titles[test_index]\n",
    "    y_train, y_test = classes[train_index], classes[test_index]\n",
    "    c.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = c.predict(X_test)\n",
    "    f_score = sklearn.metrics.f1_score(y_test, predictions, average='macro')\n",
    "    precision = sklearn.metrics.precision_score(y_test, predictions, average='macro')\n",
    "    recall = sklearn.metrics.recall_score(y_test, predictions, average='macro')\n",
    "    acc = sklearn.metrics.accuracy_score(y_test, predictions)\n",
    "    print(\"F Score:\", f_score, \"Precision\", precision, \"Recall\", recall, \"Accuracy\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from classifier import Classifier\n",
    "\n",
    "c = Classifier(\"trained_word2vec\")\n",
    "\n",
    "# Load Data\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth ['books' 'toysgames' 'sportsoutdoors' 'cellphonesaccessories'\n",
      " 'clothingshoesjewelry' 'clothingshoesjewelry' 'clothingshoesjewelry'\n",
      " 'homekitchen' 'automotive' 'toolshomeimprovement']\n",
      "Predicted ['books' 'homekitchen' 'automotive' 'cellphonesaccessories'\n",
      " 'clothingshoesjewelry' 'clothingshoesjewelry' 'clothingshoesjewelry'\n",
      " 'clothingshoesjewelry' 'automotive' 'electronics']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fit KNN (word2vec already fit)\n",
    "c.fit(np.array(df_train[\"title\"].astype(str))[:10000], np.array(df_train[\"categories\"].astype(str))[:10000])\n",
    "\n",
    "# Simple exampe\n",
    "print(\"Ground Truth\", np.array(df_test[\"categories\"])[:10])\n",
    "print(\"Predicted\", c.predict(np.array(df_test[\"title\"]))[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
