{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstrate Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from CONFIG import PREPROCESSED_DATA_PATH\n",
    "from knn import KNN\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader\n",
    "from classifier import Classifier\n",
    "from word2vec import Word2VecModel\n",
    "import math\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up some configs\n",
    "SHOULD_RETRAIN_WORD2VEC = False\n",
    "WORD2VEC_PATH = \"custom_word_2_vec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and shuffle\n",
    "df_data = pd.read_parquet(PREPROCESSED_DATA_PATH)\n",
    "df_data = df_data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if SHOULD_RETRAIN_WORD2VEC:\n",
    "    # Configure data\n",
    "    dataset_size_limt = 100000 #len(df_data)#10000\n",
    "    df_data = df_data[:dataset_size_limt]\n",
    "    test_subset = df_data[:int(len(df_data)*0.2)]\n",
    "    train_subset = df_data[int(len(df_data)*0.2):]\n",
    "    \n",
    "    # Fit the word2vec model\n",
    "    training_tokens = np.array([x.split() for x in train_subset[\"title\"]])\n",
    "    w2v_custom = Word2VecModel()\n",
    "    w2v_custom.fit(training_tokens, epochs=2048, batch_size=8192)\n",
    "    \n",
    "    # Save the word 2 vec model\n",
    "    w2v_custom.save(WORD2VEC_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "c = Classifier(WORD2VEC_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df_data.sample(frac=1).reset_index(drop=True)\n",
    "classes = np.array(df_data[\"categories\"])\n",
    "classes = classes[:10000]\n",
    "titles = np.array(df_data[\"title\"])\n",
    "titles = titles[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.fit(titles, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHOULD_RUN_K_FOLD = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if SHOULD_RUN_K_FOLD:\n",
    "    kf = KFold(n_splits=10)\n",
    "    i = 0\n",
    "    for train_index, test_index in kf.split(titles):\n",
    "        print(\"FOLD \", i)\n",
    "        X_train, X_test = titles[train_index], titles[test_index]\n",
    "        y_train, y_test = classes[train_index], classes[test_index]\n",
    "        c.fit(X_train, y_train)\n",
    "\n",
    "        predictions = c.predict(X_test)\n",
    "        f_score = sklearn.metrics.f1_score(y_test, predictions, average='macro')\n",
    "        precision = sklearn.metrics.precision_score(y_test, predictions, average='macro')\n",
    "        recall = sklearn.metrics.recall_score(y_test, predictions, average='macro')\n",
    "        acc = sklearn.metrics.accuracy_score(y_test, predictions)\n",
    "        print(\"F Score:\", f_score, \"Precision\", precision, \"Recall\", recall, \"Accuracy\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cellphonesaccessories\n"
     ]
    }
   ],
   "source": [
    "test = [\"apple iphone 5 new 4g lte for all carrier red textured skin\"]\n",
    "#print(c.predict(test)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = [\"iphone cable\"]\n",
    "#print(c.predict(test)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [\"star trek\"]\n",
    "#print(c.predict(test)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [\"oliver twist\"]\n",
    "#print(c.predict(test)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [\"dish set\"]\n",
    "#print(c.predict(test)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
